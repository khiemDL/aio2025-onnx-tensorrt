{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19068cdf",
   "metadata": {},
   "source": [
    "# PyTorch → ONNX → TensorRT\n",
    "\n",
    "Simple conversion pipeline for ResNet50:\n",
    "- Load PyTorch model\n",
    "- Export to ONNX\n",
    "- Build TensorRT engine\n",
    "- Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1d01b",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c434c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q tensorrt==10.0.1 --extra-index-url https://pypi.nvidia.com\n",
    "!pip install -q onnx pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27434178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.7.1+cu118\n",
      "CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import onnx\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "ONNX_PATH = 'models/resnet50.onnx'\n",
    "TENSORRT_PATH = 'models/resnet50.engine'\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5239f",
   "metadata": {},
   "source": [
    "## 2. Load Model & Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb4090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded ResNet50\n"
     ]
    }
   ],
   "source": [
    "# Load PyTorch ResNet50\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "model.eval()\n",
    "print(f'✅ Loaded ResNet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49bef52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved ONNX: models/resnet50.onnx\n"
     ]
    }
   ],
   "source": [
    "# Convert to ONNX\n",
    "dummy_input = torch.randn(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE)\n",
    "torch.onnx.export(\n",
    "    model.cpu(),\n",
    "    dummy_input,\n",
    "    ONNX_PATH,\n",
    "    opset_version=18,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}}\n",
    ")\n",
    "\n",
    "onnx.checker.check_model(onnx.load(ONNX_PATH))\n",
    "print(f'✅ Saved ONNX: {ONNX_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d8d517",
   "metadata": {},
   "source": [
    "## 3. Convert to TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1cdffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FP16 enabled\n",
      "Building engine (may take a few minutes)...\n",
      "✅ Saved TensorRT engine: models/resnet50.engine\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "logger = trt.Logger(trt.Logger.WARNING)\n",
    "builder = trt.Builder(logger)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "\n",
    "# Parse ONNX\n",
    "with open(ONNX_PATH, 'rb') as f:\n",
    "    parser.parse(f.read())\n",
    "\n",
    "# Configure engine\n",
    "config = builder.create_builder_config()\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "\n",
    "# Set dynamic batch profile\n",
    "profile = builder.create_optimization_profile()\n",
    "profile.set_shape('input', (1, 3, IMG_SIZE, IMG_SIZE), (1, 3, IMG_SIZE, IMG_SIZE), (8, 3, IMG_SIZE, IMG_SIZE))\n",
    "config.add_optimization_profile(profile)\n",
    "\n",
    "# Enable FP16 if available\n",
    "if builder.platform_has_fast_fp16:\n",
    "    config.set_flag(trt.BuilderFlag.FP16)\n",
    "    print('✅ FP16 enabled')\n",
    "\n",
    "# Build and save\n",
    "print('Building engine (may take a few minutes)...')\n",
    "engine = builder.build_serialized_network(network, config)\n",
    "with open(TENSORRT_PATH, 'wb') as f:\n",
    "    f.write(engine)\n",
    "\n",
    "print(f'✅ Saved TensorRT engine: {TENSORRT_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c8cbb",
   "metadata": {},
   "source": [
    "## 4. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ba1979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/20/2026-20:23:14] [TRT] [W] WARNING The logger passed into createInferRuntime differs from one already registered for an existing builder, runtime, or refitter. So the current new logger is ignored, and TensorRT will use the existing one which is returned by nvinfer1::getLogger() instead.\n",
      "✅ Inference completed\n",
      "Top-5 classes: [490 904 828 488 446]\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "# Load engine\n",
    "with open(TENSORRT_PATH, 'rb') as f:\n",
    "    runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING))\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "# Get tensor names\n",
    "input_name = engine.get_tensor_name(0)\n",
    "output_name = engine.get_tensor_name(1)\n",
    "\n",
    "# Set input shape\n",
    "input_shape = (BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE)\n",
    "context.set_input_shape(input_name, input_shape)\n",
    "output_shape = context.get_tensor_shape(output_name)\n",
    "\n",
    "# Allocate memory\n",
    "h_input = np.random.randn(*input_shape).astype(np.float32)\n",
    "h_output = np.empty(output_shape, dtype=np.float32)\n",
    "d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "stream = cuda.Stream()\n",
    "\n",
    "# Set tensor addresses\n",
    "context.set_tensor_address(input_name, int(d_input))\n",
    "context.set_tensor_address(output_name, int(d_output))\n",
    "\n",
    "# Run inference\n",
    "cuda.memcpy_htod_async(d_input, h_input, stream)\n",
    "context.execute_async_v3(stream_handle=stream.handle)\n",
    "cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "stream.synchronize()\n",
    "\n",
    "# Results\n",
    "print(f'✅ Inference completed')\n",
    "print(f'Top-5 classes: {np.argsort(h_output[0])[-5:][::-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
