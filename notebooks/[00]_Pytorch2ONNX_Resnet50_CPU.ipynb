{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH-TPh0YZJ1p"
      },
      "source": [
        "# 1. Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5WmW8JQWKd9",
        "outputId": "59db6003-81f4-4ddc-cc26-1813ca540c29"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision onnx onnxruntime onnxscript tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HM_yio3CZjdO",
        "outputId": "0361cf13-f552-44fa-b41a-e8f6a8f82930"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.20.1'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import onnx\n",
        "onnx.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.23.2\n",
            "['AzureExecutionProvider', 'CPUExecutionProvider']\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime as ort\n",
        "print(ort.__version__)\n",
        "print(ort.get_available_providers())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('2.9.1+cu128', True)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__, torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0NTqz13ZOOr"
      },
      "source": [
        "# 2. Load Pytorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK0MQisCZ0cK",
        "outputId": "4d0d12c6-0ba4-4f19-b30e-0013e42de35e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "torch_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "torch_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTiMR7zTZ4Dm"
      },
      "source": [
        "# 3. Convert to ONNX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-F4XiMHaBfM"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RwIGOQGxaDfc"
      },
      "outputs": [],
      "source": [
        "ONNX_PATH = \"./resnet50.onnx\"\n",
        "IMG_SIZE = 224\n",
        "OPSET = 18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w53RJHEmaEsc"
      },
      "source": [
        "## Dummy input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V8YeWJJeaHt0"
      },
      "outputs": [],
      "source": [
        "dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCb1wMW6aNBZ"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jpHtxbxaK0k",
        "outputId": "9b70adea-902e-4ffa-bcff-71e1cafdc26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 106 of general pattern rewrite rules.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ONNXProgram(\n",
              "    model=\n",
              "        <\n",
              "            ir_version=10,\n",
              "            opset_imports={'': 18},\n",
              "            producer_name='pytorch',\n",
              "            producer_version='2.9.1+cu128',\n",
              "            domain=None,\n",
              "            model_version=None,\n",
              "        >\n",
              "        graph(\n",
              "            name=main_graph,\n",
              "            inputs=(\n",
              "                %\"input\"<FLOAT,[1,3,224,224]>\n",
              "            ),\n",
              "            outputs=(\n",
              "                %\"output\"<FLOAT,[1,1000]>\n",
              "            ),\n",
              "            initializers=(\n",
              "                %\"conv1.weight\"<FLOAT,[64,3,7,7]>{Tensor(...)},\n",
              "                %\"layer1.0.conv1.weight\"<FLOAT,[64,64,1,1]>{Tensor(...)},\n",
              "                %\"layer1.0.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
              "                %\"layer1.0.conv3.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
              "                %\"layer1.0.downsample.0.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
              "                %\"layer1.1.conv1.weight\"<FLOAT,[64,256,1,1]>{Tensor(...)},\n",
              "                %\"layer1.1.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
              "                %\"layer1.1.conv3.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
              "                %\"layer1.2.conv1.weight\"<FLOAT,[64,256,1,1]>{Tensor(...)},\n",
              "                %\"layer1.2.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
              "                %\"layer1.2.conv3.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
              "                %\"layer2.0.conv1.weight\"<FLOAT,[128,256,1,1]>{Tensor(...)},\n",
              "                %\"layer2.0.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
              "                %\"layer2.0.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
              "                %\"layer2.0.downsample.0.weight\"<FLOAT,[512,256,1,1]>{Tensor(...)},\n",
              "                %\"layer2.1.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
              "                %\"layer2.1.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
              "                %\"layer2.1.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
              "                %\"layer2.2.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
              "                %\"layer2.2.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
              "                %\"layer2.2.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
              "                %\"layer2.3.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
              "                %\"layer2.3.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
              "                %\"layer2.3.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
              "                %\"layer3.0.conv1.weight\"<FLOAT,[256,512,1,1]>{Tensor(...)},\n",
              "                %\"layer3.0.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer3.0.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
              "                %\"layer3.0.downsample.0.weight\"<FLOAT,[1024,512,1,1]>{Tensor(...)},\n",
              "                %\"layer3.1.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
              "                %\"layer3.1.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer3.1.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
              "                %\"layer3.2.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
              "                %\"layer3.2.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer3.2.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
              "                %\"layer3.3.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
              "                %\"layer3.3.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer3.3.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
              "                %\"layer3.4.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
              "                %\"layer3.4.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer3.4.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
              "                %\"layer3.5.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
              "                %\"layer3.5.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
              "                %\"layer3.5.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
              "                %\"layer4.0.conv1.weight\"<FLOAT,[512,1024,1,1]>{Tensor(...)},\n",
              "                %\"layer4.0.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
              "                %\"layer4.0.conv3.weight\"<FLOAT,[2048,512,1,1]>{Tensor(...)},\n",
              "                %\"layer4.0.downsample.0.weight\"<FLOAT,[2048,1024,1,1]>{Tensor(...)},\n",
              "                %\"layer4.1.conv1.weight\"<FLOAT,[512,2048,1,1]>{Tensor(...)},\n",
              "                %\"layer4.1.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
              "                %\"layer4.1.conv3.weight\"<FLOAT,[2048,512,1,1]>{Tensor(...)},\n",
              "                %\"layer4.2.conv1.weight\"<FLOAT,[512,2048,1,1]>{Tensor(...)},\n",
              "                %\"layer4.2.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
              "                %\"layer4.2.conv3.weight\"<FLOAT,[2048,512,1,1]>{Tensor(...)},\n",
              "                %\"fc.weight\"<FLOAT,[1000,2048]>{TorchTensor(...)},\n",
              "                %\"fc.bias\"<FLOAT,[1000]>{TorchTensor(...)},\n",
              "                %\"val_483\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_483')},\n",
              "                %\"val_487\"<INT64,[2]>{Tensor<INT64,[2]>(array([   1, 2048]), name='val_487')},\n",
              "                %\"conv1.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.0.conv1.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.0.conv2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.0.conv3.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer1.0.downsample.0.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer1.1.conv1.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.1.conv2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.1.conv3.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer1.2.conv1.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.2.conv2.weight_bias\"<FLOAT,[64]>{Tensor(...)},\n",
              "                %\"layer1.2.conv3.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer2.0.conv1.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.0.conv2.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.0.conv3.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer2.0.downsample.0.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer2.1.conv1.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.1.conv2.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.1.conv3.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer2.2.conv1.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.2.conv2.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.2.conv3.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer2.3.conv1.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.3.conv2.weight_bias\"<FLOAT,[128]>{Tensor(...)},\n",
              "                %\"layer2.3.conv3.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer3.0.conv1.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.0.conv2.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.0.conv3.weight_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
              "                %\"layer3.0.downsample.0.weight_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
              "                %\"layer3.1.conv1.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.1.conv2.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.1.conv3.weight_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
              "                %\"layer3.2.conv1.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.2.conv2.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.2.conv3.weight_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
              "                %\"layer3.3.conv1.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.3.conv2.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.3.conv3.weight_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
              "                %\"layer3.4.conv1.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.4.conv2.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.4.conv3.weight_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
              "                %\"layer3.5.conv1.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.5.conv2.weight_bias\"<FLOAT,[256]>{Tensor(...)},\n",
              "                %\"layer3.5.conv3.weight_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
              "                %\"layer4.0.conv1.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.0.conv2.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.0.conv3.weight_bias\"<FLOAT,[2048]>{Tensor(...)},\n",
              "                %\"layer4.0.downsample.0.weight_bias\"<FLOAT,[2048]>{Tensor(...)},\n",
              "                %\"layer4.1.conv1.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.1.conv2.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.1.conv3.weight_bias\"<FLOAT,[2048]>{Tensor(...)},\n",
              "                %\"layer4.2.conv1.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.2.conv2.weight_bias\"<FLOAT,[512]>{Tensor(...)},\n",
              "                %\"layer4.2.conv3.weight_bias\"<FLOAT,[2048]>{Tensor(...)}\n",
              "            ),\n",
              "        ) {\n",
              "              0 |  # node_Conv_647\n",
              "                   %\"getitem\"<FLOAT,[1,64,112,112]> ⬅️ ::Conv(%\"input\", %\"conv1.weight\"{...}, %\"conv1.weight_bias\"{...}) {group=1, pads=(3, 3, 3, 3), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "              1 |  # node_relu\n",
              "                   %\"relu\"<FLOAT,[1,64,112,112]> ⬅️ ::Relu(%\"getitem\")\n",
              "              2 |  # node_max_pool2d\n",
              "                   %\"max_pool2d\"<FLOAT,[1,64,56,56]> ⬅️ ::MaxPool(%\"relu\") {storage_order=0, dilations=(1, 1), ceil_mode=0, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), kernel_shape=(3, 3)}\n",
              "              3 |  # node_Conv_649\n",
              "                   %\"getitem_3\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"max_pool2d\", %\"layer1.0.conv1.weight\"{...}, %\"layer1.0.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "              4 |  # node_relu_1\n",
              "                   %\"relu_1\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_3\")\n",
              "              5 |  # node_Conv_651\n",
              "                   %\"getitem_6\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_1\", %\"layer1.0.conv2.weight\"{...}, %\"layer1.0.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "              6 |  # node_relu_2\n",
              "                   %\"relu_2\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_6\")\n",
              "              7 |  # node_Conv_653\n",
              "                   %\"getitem_9\"<FLOAT,[1,256,56,56]> ⬅️ ::Conv(%\"relu_2\", %\"layer1.0.conv3.weight\"{...}, %\"layer1.0.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "              8 |  # node_Conv_655\n",
              "                   %\"getitem_12\"<FLOAT,[1,256,56,56]> ⬅️ ::Conv(%\"max_pool2d\", %\"layer1.0.downsample.0.weight\"{...}, %\"layer1.0.downsample.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "              9 |  # node_add\n",
              "                   %\"add\"<FLOAT,[1,256,56,56]> ⬅️ ::Add(%\"getitem_9\", %\"getitem_12\")\n",
              "             10 |  # node_relu_3\n",
              "                   %\"relu_3\"<FLOAT,[1,256,56,56]> ⬅️ ::Relu(%\"add\")\n",
              "             11 |  # node_Conv_657\n",
              "                   %\"getitem_15\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_3\", %\"layer1.1.conv1.weight\"{...}, %\"layer1.1.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             12 |  # node_relu_4\n",
              "                   %\"relu_4\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_15\")\n",
              "             13 |  # node_Conv_659\n",
              "                   %\"getitem_18\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_4\", %\"layer1.1.conv2.weight\"{...}, %\"layer1.1.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             14 |  # node_relu_5\n",
              "                   %\"relu_5\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_18\")\n",
              "             15 |  # node_Conv_661\n",
              "                   %\"getitem_21\"<FLOAT,[1,256,56,56]> ⬅️ ::Conv(%\"relu_5\", %\"layer1.1.conv3.weight\"{...}, %\"layer1.1.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             16 |  # node_add_1\n",
              "                   %\"add_1\"<FLOAT,[1,256,56,56]> ⬅️ ::Add(%\"getitem_21\", %\"relu_3\")\n",
              "             17 |  # node_relu_6\n",
              "                   %\"relu_6\"<FLOAT,[1,256,56,56]> ⬅️ ::Relu(%\"add_1\")\n",
              "             18 |  # node_Conv_663\n",
              "                   %\"getitem_24\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_6\", %\"layer1.2.conv1.weight\"{...}, %\"layer1.2.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             19 |  # node_relu_7\n",
              "                   %\"relu_7\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_24\")\n",
              "             20 |  # node_Conv_665\n",
              "                   %\"getitem_27\"<FLOAT,[1,64,56,56]> ⬅️ ::Conv(%\"relu_7\", %\"layer1.2.conv2.weight\"{...}, %\"layer1.2.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             21 |  # node_relu_8\n",
              "                   %\"relu_8\"<FLOAT,[1,64,56,56]> ⬅️ ::Relu(%\"getitem_27\")\n",
              "             22 |  # node_Conv_667\n",
              "                   %\"getitem_30\"<FLOAT,[1,256,56,56]> ⬅️ ::Conv(%\"relu_8\", %\"layer1.2.conv3.weight\"{...}, %\"layer1.2.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             23 |  # node_add_2\n",
              "                   %\"add_2\"<FLOAT,[1,256,56,56]> ⬅️ ::Add(%\"getitem_30\", %\"relu_6\")\n",
              "             24 |  # node_relu_9\n",
              "                   %\"relu_9\"<FLOAT,[1,256,56,56]> ⬅️ ::Relu(%\"add_2\")\n",
              "             25 |  # node_Conv_669\n",
              "                   %\"getitem_33\"<FLOAT,[1,128,56,56]> ⬅️ ::Conv(%\"relu_9\", %\"layer2.0.conv1.weight\"{...}, %\"layer2.0.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             26 |  # node_relu_10\n",
              "                   %\"relu_10\"<FLOAT,[1,128,56,56]> ⬅️ ::Relu(%\"getitem_33\")\n",
              "             27 |  # node_Conv_671\n",
              "                   %\"getitem_36\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_10\", %\"layer2.0.conv2.weight\"{...}, %\"layer2.0.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             28 |  # node_relu_11\n",
              "                   %\"relu_11\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_36\")\n",
              "             29 |  # node_Conv_673\n",
              "                   %\"getitem_39\"<FLOAT,[1,512,28,28]> ⬅️ ::Conv(%\"relu_11\", %\"layer2.0.conv3.weight\"{...}, %\"layer2.0.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             30 |  # node_Conv_675\n",
              "                   %\"getitem_42\"<FLOAT,[1,512,28,28]> ⬅️ ::Conv(%\"relu_9\", %\"layer2.0.downsample.0.weight\"{...}, %\"layer2.0.downsample.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             31 |  # node_add_3\n",
              "                   %\"add_3\"<FLOAT,[1,512,28,28]> ⬅️ ::Add(%\"getitem_39\", %\"getitem_42\")\n",
              "             32 |  # node_relu_12\n",
              "                   %\"relu_12\"<FLOAT,[1,512,28,28]> ⬅️ ::Relu(%\"add_3\")\n",
              "             33 |  # node_Conv_677\n",
              "                   %\"getitem_45\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_12\", %\"layer2.1.conv1.weight\"{...}, %\"layer2.1.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             34 |  # node_relu_13\n",
              "                   %\"relu_13\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_45\")\n",
              "             35 |  # node_Conv_679\n",
              "                   %\"getitem_48\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_13\", %\"layer2.1.conv2.weight\"{...}, %\"layer2.1.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             36 |  # node_relu_14\n",
              "                   %\"relu_14\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_48\")\n",
              "             37 |  # node_Conv_681\n",
              "                   %\"getitem_51\"<FLOAT,[1,512,28,28]> ⬅️ ::Conv(%\"relu_14\", %\"layer2.1.conv3.weight\"{...}, %\"layer2.1.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             38 |  # node_add_4\n",
              "                   %\"add_4\"<FLOAT,[1,512,28,28]> ⬅️ ::Add(%\"getitem_51\", %\"relu_12\")\n",
              "             39 |  # node_relu_15\n",
              "                   %\"relu_15\"<FLOAT,[1,512,28,28]> ⬅️ ::Relu(%\"add_4\")\n",
              "             40 |  # node_Conv_683\n",
              "                   %\"getitem_54\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_15\", %\"layer2.2.conv1.weight\"{...}, %\"layer2.2.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             41 |  # node_relu_16\n",
              "                   %\"relu_16\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_54\")\n",
              "             42 |  # node_Conv_685\n",
              "                   %\"getitem_57\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_16\", %\"layer2.2.conv2.weight\"{...}, %\"layer2.2.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             43 |  # node_relu_17\n",
              "                   %\"relu_17\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_57\")\n",
              "             44 |  # node_Conv_687\n",
              "                   %\"getitem_60\"<FLOAT,[1,512,28,28]> ⬅️ ::Conv(%\"relu_17\", %\"layer2.2.conv3.weight\"{...}, %\"layer2.2.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             45 |  # node_add_5\n",
              "                   %\"add_5\"<FLOAT,[1,512,28,28]> ⬅️ ::Add(%\"getitem_60\", %\"relu_15\")\n",
              "             46 |  # node_relu_18\n",
              "                   %\"relu_18\"<FLOAT,[1,512,28,28]> ⬅️ ::Relu(%\"add_5\")\n",
              "             47 |  # node_Conv_689\n",
              "                   %\"getitem_63\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_18\", %\"layer2.3.conv1.weight\"{...}, %\"layer2.3.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             48 |  # node_relu_19\n",
              "                   %\"relu_19\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_63\")\n",
              "             49 |  # node_Conv_691\n",
              "                   %\"getitem_66\"<FLOAT,[1,128,28,28]> ⬅️ ::Conv(%\"relu_19\", %\"layer2.3.conv2.weight\"{...}, %\"layer2.3.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             50 |  # node_relu_20\n",
              "                   %\"relu_20\"<FLOAT,[1,128,28,28]> ⬅️ ::Relu(%\"getitem_66\")\n",
              "             51 |  # node_Conv_693\n",
              "                   %\"getitem_69\"<FLOAT,[1,512,28,28]> ⬅️ ::Conv(%\"relu_20\", %\"layer2.3.conv3.weight\"{...}, %\"layer2.3.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             52 |  # node_add_6\n",
              "                   %\"add_6\"<FLOAT,[1,512,28,28]> ⬅️ ::Add(%\"getitem_69\", %\"relu_18\")\n",
              "             53 |  # node_relu_21\n",
              "                   %\"relu_21\"<FLOAT,[1,512,28,28]> ⬅️ ::Relu(%\"add_6\")\n",
              "             54 |  # node_Conv_695\n",
              "                   %\"getitem_72\"<FLOAT,[1,256,28,28]> ⬅️ ::Conv(%\"relu_21\", %\"layer3.0.conv1.weight\"{...}, %\"layer3.0.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             55 |  # node_relu_22\n",
              "                   %\"relu_22\"<FLOAT,[1,256,28,28]> ⬅️ ::Relu(%\"getitem_72\")\n",
              "             56 |  # node_Conv_697\n",
              "                   %\"getitem_75\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_22\", %\"layer3.0.conv2.weight\"{...}, %\"layer3.0.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             57 |  # node_relu_23\n",
              "                   %\"relu_23\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_75\")\n",
              "             58 |  # node_Conv_699\n",
              "                   %\"getitem_78\"<FLOAT,[1,1024,14,14]> ⬅️ ::Conv(%\"relu_23\", %\"layer3.0.conv3.weight\"{...}, %\"layer3.0.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             59 |  # node_Conv_701\n",
              "                   %\"getitem_81\"<FLOAT,[1,1024,14,14]> ⬅️ ::Conv(%\"relu_21\", %\"layer3.0.downsample.0.weight\"{...}, %\"layer3.0.downsample.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             60 |  # node_add_7\n",
              "                   %\"add_7\"<FLOAT,[1,1024,14,14]> ⬅️ ::Add(%\"getitem_78\", %\"getitem_81\")\n",
              "             61 |  # node_relu_24\n",
              "                   %\"relu_24\"<FLOAT,[1,1024,14,14]> ⬅️ ::Relu(%\"add_7\")\n",
              "             62 |  # node_Conv_703\n",
              "                   %\"getitem_84\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_24\", %\"layer3.1.conv1.weight\"{...}, %\"layer3.1.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             63 |  # node_relu_25\n",
              "                   %\"relu_25\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_84\")\n",
              "             64 |  # node_Conv_705\n",
              "                   %\"getitem_87\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_25\", %\"layer3.1.conv2.weight\"{...}, %\"layer3.1.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             65 |  # node_relu_26\n",
              "                   %\"relu_26\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_87\")\n",
              "             66 |  # node_Conv_707\n",
              "                   %\"getitem_90\"<FLOAT,[1,1024,14,14]> ⬅️ ::Conv(%\"relu_26\", %\"layer3.1.conv3.weight\"{...}, %\"layer3.1.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             67 |  # node_add_8\n",
              "                   %\"add_8\"<FLOAT,[1,1024,14,14]> ⬅️ ::Add(%\"getitem_90\", %\"relu_24\")\n",
              "             68 |  # node_relu_27\n",
              "                   %\"relu_27\"<FLOAT,[1,1024,14,14]> ⬅️ ::Relu(%\"add_8\")\n",
              "             69 |  # node_Conv_709\n",
              "                   %\"getitem_93\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_27\", %\"layer3.2.conv1.weight\"{...}, %\"layer3.2.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             70 |  # node_relu_28\n",
              "                   %\"relu_28\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_93\")\n",
              "             71 |  # node_Conv_711\n",
              "                   %\"getitem_96\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_28\", %\"layer3.2.conv2.weight\"{...}, %\"layer3.2.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             72 |  # node_relu_29\n",
              "                   %\"relu_29\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_96\")\n",
              "             73 |  # node_Conv_713\n",
              "                   %\"getitem_99\"<FLOAT,[1,1024,14,14]> ⬅️ ::Conv(%\"relu_29\", %\"layer3.2.conv3.weight\"{...}, %\"layer3.2.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             74 |  # node_add_9\n",
              "                   %\"add_9\"<FLOAT,[1,1024,14,14]> ⬅️ ::Add(%\"getitem_99\", %\"relu_27\")\n",
              "             75 |  # node_relu_30\n",
              "                   %\"relu_30\"<FLOAT,[1,1024,14,14]> ⬅️ ::Relu(%\"add_9\")\n",
              "             76 |  # node_Conv_715\n",
              "                   %\"getitem_102\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_30\", %\"layer3.3.conv1.weight\"{...}, %\"layer3.3.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             77 |  # node_relu_31\n",
              "                   %\"relu_31\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_102\")\n",
              "             78 |  # node_Conv_717\n",
              "                   %\"getitem_105\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_31\", %\"layer3.3.conv2.weight\"{...}, %\"layer3.3.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             79 |  # node_relu_32\n",
              "                   %\"relu_32\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_105\")\n",
              "             80 |  # node_Conv_719\n",
              "                   %\"getitem_108\"<FLOAT,[1,1024,14,14]> ⬅️ ::Conv(%\"relu_32\", %\"layer3.3.conv3.weight\"{...}, %\"layer3.3.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             81 |  # node_add_10\n",
              "                   %\"add_10\"<FLOAT,[1,1024,14,14]> ⬅️ ::Add(%\"getitem_108\", %\"relu_30\")\n",
              "             82 |  # node_relu_33\n",
              "                   %\"relu_33\"<FLOAT,[1,1024,14,14]> ⬅️ ::Relu(%\"add_10\")\n",
              "             83 |  # node_Conv_721\n",
              "                   %\"getitem_111\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_33\", %\"layer3.4.conv1.weight\"{...}, %\"layer3.4.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             84 |  # node_relu_34\n",
              "                   %\"relu_34\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_111\")\n",
              "             85 |  # node_Conv_723\n",
              "                   %\"getitem_114\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_34\", %\"layer3.4.conv2.weight\"{...}, %\"layer3.4.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             86 |  # node_relu_35\n",
              "                   %\"relu_35\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_114\")\n",
              "             87 |  # node_Conv_725\n",
              "                   %\"getitem_117\"<FLOAT,[1,1024,14,14]> ⬅️ ::Conv(%\"relu_35\", %\"layer3.4.conv3.weight\"{...}, %\"layer3.4.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             88 |  # node_add_11\n",
              "                   %\"add_11\"<FLOAT,[1,1024,14,14]> ⬅️ ::Add(%\"getitem_117\", %\"relu_33\")\n",
              "             89 |  # node_relu_36\n",
              "                   %\"relu_36\"<FLOAT,[1,1024,14,14]> ⬅️ ::Relu(%\"add_11\")\n",
              "             90 |  # node_Conv_727\n",
              "                   %\"getitem_120\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_36\", %\"layer3.5.conv1.weight\"{...}, %\"layer3.5.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             91 |  # node_relu_37\n",
              "                   %\"relu_37\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_120\")\n",
              "             92 |  # node_Conv_729\n",
              "                   %\"getitem_123\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"relu_37\", %\"layer3.5.conv2.weight\"{...}, %\"layer3.5.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             93 |  # node_relu_38\n",
              "                   %\"relu_38\"<FLOAT,[1,256,14,14]> ⬅️ ::Relu(%\"getitem_123\")\n",
              "             94 |  # node_Conv_731\n",
              "                   %\"getitem_126\"<FLOAT,[1,1024,14,14]> ⬅️ ::Conv(%\"relu_38\", %\"layer3.5.conv3.weight\"{...}, %\"layer3.5.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             95 |  # node_add_12\n",
              "                   %\"add_12\"<FLOAT,[1,1024,14,14]> ⬅️ ::Add(%\"getitem_126\", %\"relu_36\")\n",
              "             96 |  # node_relu_39\n",
              "                   %\"relu_39\"<FLOAT,[1,1024,14,14]> ⬅️ ::Relu(%\"add_12\")\n",
              "             97 |  # node_Conv_733\n",
              "                   %\"getitem_129\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"relu_39\", %\"layer4.0.conv1.weight\"{...}, %\"layer4.0.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             98 |  # node_relu_40\n",
              "                   %\"relu_40\"<FLOAT,[1,512,14,14]> ⬅️ ::Relu(%\"getitem_129\")\n",
              "             99 |  # node_Conv_735\n",
              "                   %\"getitem_132\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_40\", %\"layer4.0.conv2.weight\"{...}, %\"layer4.0.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            100 |  # node_relu_41\n",
              "                   %\"relu_41\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_132\")\n",
              "            101 |  # node_Conv_737\n",
              "                   %\"getitem_135\"<FLOAT,[1,2048,7,7]> ⬅️ ::Conv(%\"relu_41\", %\"layer4.0.conv3.weight\"{...}, %\"layer4.0.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            102 |  # node_Conv_739\n",
              "                   %\"getitem_138\"<FLOAT,[1,2048,7,7]> ⬅️ ::Conv(%\"relu_39\", %\"layer4.0.downsample.0.weight\"{...}, %\"layer4.0.downsample.0.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "            103 |  # node_add_13\n",
              "                   %\"add_13\"<FLOAT,[1,2048,7,7]> ⬅️ ::Add(%\"getitem_135\", %\"getitem_138\")\n",
              "            104 |  # node_relu_42\n",
              "                   %\"relu_42\"<FLOAT,[1,2048,7,7]> ⬅️ ::Relu(%\"add_13\")\n",
              "            105 |  # node_Conv_741\n",
              "                   %\"getitem_141\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_42\", %\"layer4.1.conv1.weight\"{...}, %\"layer4.1.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            106 |  # node_relu_43\n",
              "                   %\"relu_43\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_141\")\n",
              "            107 |  # node_Conv_743\n",
              "                   %\"getitem_144\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_43\", %\"layer4.1.conv2.weight\"{...}, %\"layer4.1.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            108 |  # node_relu_44\n",
              "                   %\"relu_44\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_144\")\n",
              "            109 |  # node_Conv_745\n",
              "                   %\"getitem_147\"<FLOAT,[1,2048,7,7]> ⬅️ ::Conv(%\"relu_44\", %\"layer4.1.conv3.weight\"{...}, %\"layer4.1.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            110 |  # node_add_14\n",
              "                   %\"add_14\"<FLOAT,[1,2048,7,7]> ⬅️ ::Add(%\"getitem_147\", %\"relu_42\")\n",
              "            111 |  # node_relu_45\n",
              "                   %\"relu_45\"<FLOAT,[1,2048,7,7]> ⬅️ ::Relu(%\"add_14\")\n",
              "            112 |  # node_Conv_747\n",
              "                   %\"getitem_150\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_45\", %\"layer4.2.conv1.weight\"{...}, %\"layer4.2.conv1.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            113 |  # node_relu_46\n",
              "                   %\"relu_46\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_150\")\n",
              "            114 |  # node_Conv_749\n",
              "                   %\"getitem_153\"<FLOAT,[1,512,7,7]> ⬅️ ::Conv(%\"relu_46\", %\"layer4.2.conv2.weight\"{...}, %\"layer4.2.conv2.weight_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            115 |  # node_relu_47\n",
              "                   %\"relu_47\"<FLOAT,[1,512,7,7]> ⬅️ ::Relu(%\"getitem_153\")\n",
              "            116 |  # node_Conv_751\n",
              "                   %\"getitem_156\"<FLOAT,[1,2048,7,7]> ⬅️ ::Conv(%\"relu_47\", %\"layer4.2.conv3.weight\"{...}, %\"layer4.2.conv3.weight_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            117 |  # node_add_15\n",
              "                   %\"add_15\"<FLOAT,[1,2048,7,7]> ⬅️ ::Add(%\"getitem_156\", %\"relu_45\")\n",
              "            118 |  # node_relu_48\n",
              "                   %\"relu_48\"<FLOAT,[1,2048,7,7]> ⬅️ ::Relu(%\"add_15\")\n",
              "            119 |  # node_mean\n",
              "                   %\"mean\"<FLOAT,[1,2048,1,1]> ⬅️ ::ReduceMean(%\"relu_48\", %\"val_483\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
              "            120 |  # node_view\n",
              "                   %\"view\"<FLOAT,[1,2048]> ⬅️ ::Reshape(%\"mean\", %\"val_487\"{[1, 2048]}) {allowzero=1}\n",
              "            121 |  # node_linear\n",
              "                   %\"output\"<FLOAT,[1,1000]> ⬅️ ::Gemm(%\"view\", %\"fc.weight\"{...}, %\"fc.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            return %\"output\"<FLOAT,[1,1000]>\n",
              "        }\n",
              "\n",
              "\n",
              "    ,\n",
              "    exported_program=\n",
              "        ExportedProgram:\n",
              "            class GraphModule(torch.nn.Module):\n",
              "                def forward(self, p_conv1_weight: \"f32[64, 3, 7, 7]\", p_bn1_weight: \"f32[64]\", p_bn1_bias: \"f32[64]\", p_layer1_0_conv1_weight: \"f32[64, 64, 1, 1]\", p_layer1_0_bn1_weight: \"f32[64]\", p_layer1_0_bn1_bias: \"f32[64]\", p_layer1_0_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_0_bn2_weight: \"f32[64]\", p_layer1_0_bn2_bias: \"f32[64]\", p_layer1_0_conv3_weight: \"f32[256, 64, 1, 1]\", p_layer1_0_bn3_weight: \"f32[256]\", p_layer1_0_bn3_bias: \"f32[256]\", p_layer1_0_downsample_0_weight: \"f32[256, 64, 1, 1]\", p_layer1_0_downsample_1_weight: \"f32[256]\", p_layer1_0_downsample_1_bias: \"f32[256]\", p_layer1_1_conv1_weight: \"f32[64, 256, 1, 1]\", p_layer1_1_bn1_weight: \"f32[64]\", p_layer1_1_bn1_bias: \"f32[64]\", p_layer1_1_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_1_bn2_weight: \"f32[64]\", p_layer1_1_bn2_bias: \"f32[64]\", p_layer1_1_conv3_weight: \"f32[256, 64, 1, 1]\", p_layer1_1_bn3_weight: \"f32[256]\", p_layer1_1_bn3_bias: \"f32[256]\", p_layer1_2_conv1_weight: \"f32[64, 256, 1, 1]\", p_layer1_2_bn1_weight: \"f32[64]\", p_layer1_2_bn1_bias: \"f32[64]\", p_layer1_2_conv2_weight: \"f32[64, 64, 3, 3]\", p_layer1_2_bn2_weight: \"f32[64]\", p_layer1_2_bn2_bias: \"f32[64]\", p_layer1_2_conv3_weight: \"f32[256, 64, 1, 1]\", p_layer1_2_bn3_weight: \"f32[256]\", p_layer1_2_bn3_bias: \"f32[256]\", p_layer2_0_conv1_weight: \"f32[128, 256, 1, 1]\", p_layer2_0_bn1_weight: \"f32[128]\", p_layer2_0_bn1_bias: \"f32[128]\", p_layer2_0_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_0_bn2_weight: \"f32[128]\", p_layer2_0_bn2_bias: \"f32[128]\", p_layer2_0_conv3_weight: \"f32[512, 128, 1, 1]\", p_layer2_0_bn3_weight: \"f32[512]\", p_layer2_0_bn3_bias: \"f32[512]\", p_layer2_0_downsample_0_weight: \"f32[512, 256, 1, 1]\", p_layer2_0_downsample_1_weight: \"f32[512]\", p_layer2_0_downsample_1_bias: \"f32[512]\", p_layer2_1_conv1_weight: \"f32[128, 512, 1, 1]\", p_layer2_1_bn1_weight: \"f32[128]\", p_layer2_1_bn1_bias: \"f32[128]\", p_layer2_1_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_1_bn2_weight: \"f32[128]\", p_layer2_1_bn2_bias: \"f32[128]\", p_layer2_1_conv3_weight: \"f32[512, 128, 1, 1]\", p_layer2_1_bn3_weight: \"f32[512]\", p_layer2_1_bn3_bias: \"f32[512]\", p_layer2_2_conv1_weight: \"f32[128, 512, 1, 1]\", p_layer2_2_bn1_weight: \"f32[128]\", p_layer2_2_bn1_bias: \"f32[128]\", p_layer2_2_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_2_bn2_weight: \"f32[128]\", p_layer2_2_bn2_bias: \"f32[128]\", p_layer2_2_conv3_weight: \"f32[512, 128, 1, 1]\", p_layer2_2_bn3_weight: \"f32[512]\", p_layer2_2_bn3_bias: \"f32[512]\", p_layer2_3_conv1_weight: \"f32[128, 512, 1, 1]\", p_layer2_3_bn1_weight: \"f32[128]\", p_layer2_3_bn1_bias: \"f32[128]\", p_layer2_3_conv2_weight: \"f32[128, 128, 3, 3]\", p_layer2_3_bn2_weight: \"f32[128]\", p_layer2_3_bn2_bias: \"f32[128]\", p_layer2_3_conv3_weight: \"f32[512, 128, 1, 1]\", p_layer2_3_bn3_weight: \"f32[512]\", p_layer2_3_bn3_bias: \"f32[512]\", p_layer3_0_conv1_weight: \"f32[256, 512, 1, 1]\", p_layer3_0_bn1_weight: \"f32[256]\", p_layer3_0_bn1_bias: \"f32[256]\", p_layer3_0_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_0_bn2_weight: \"f32[256]\", p_layer3_0_bn2_bias: \"f32[256]\", p_layer3_0_conv3_weight: \"f32[1024, 256, 1, 1]\", p_layer3_0_bn3_weight: \"f32[1024]\", p_layer3_0_bn3_bias: \"f32[1024]\", p_layer3_0_downsample_0_weight: \"f32[1024, 512, 1, 1]\", p_layer3_0_downsample_1_weight: \"f32[1024]\", p_layer3_0_downsample_1_bias: \"f32[1024]\", p_layer3_1_conv1_weight: \"f32[256, 1024, 1, 1]\", p_layer3_1_bn1_weight: \"f32[256]\", p_layer3_1_bn1_bias: \"f32[256]\", p_layer3_1_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_1_bn2_weight: \"f32[256]\", p_layer3_1_bn2_bias: \"f32[256]\", p_layer3_1_conv3_weight: \"f32[1024, 256, 1, 1]\", p_layer3_1_bn3_weight: \"f32[1024]\", p_layer3_1_bn3_bias: \"f32[1024]\", p_layer3_2_conv1_weight: \"f32[256, 1024, 1, 1]\", p_layer3_2_bn1_weight: \"f32[256]\", p_layer3_2_bn1_bias: \"f32[256]\", p_layer3_2_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_2_bn2_weight: \"f32[256]\", p_layer3_2_bn2_bias: \"f32[256]\", p_layer3_2_conv3_weight: \"f32[1024, 256, 1, 1]\", p_layer3_2_bn3_weight: \"f32[1024]\", p_layer3_2_bn3_bias: \"f32[1024]\", p_layer3_3_conv1_weight: \"f32[256, 1024, 1, 1]\", p_layer3_3_bn1_weight: \"f32[256]\", p_layer3_3_bn1_bias: \"f32[256]\", p_layer3_3_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_3_bn2_weight: \"f32[256]\", p_layer3_3_bn2_bias: \"f32[256]\", p_layer3_3_conv3_weight: \"f32[1024, 256, 1, 1]\", p_layer3_3_bn3_weight: \"f32[1024]\", p_layer3_3_bn3_bias: \"f32[1024]\", p_layer3_4_conv1_weight: \"f32[256, 1024, 1, 1]\", p_layer3_4_bn1_weight: \"f32[256]\", p_layer3_4_bn1_bias: \"f32[256]\", p_layer3_4_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_4_bn2_weight: \"f32[256]\", p_layer3_4_bn2_bias: \"f32[256]\", p_layer3_4_conv3_weight: \"f32[1024, 256, 1, 1]\", p_layer3_4_bn3_weight: \"f32[1024]\", p_layer3_4_bn3_bias: \"f32[1024]\", p_layer3_5_conv1_weight: \"f32[256, 1024, 1, 1]\", p_layer3_5_bn1_weight: \"f32[256]\", p_layer3_5_bn1_bias: \"f32[256]\", p_layer3_5_conv2_weight: \"f32[256, 256, 3, 3]\", p_layer3_5_bn2_weight: \"f32[256]\", p_layer3_5_bn2_bias: \"f32[256]\", p_layer3_5_conv3_weight: \"f32[1024, 256, 1, 1]\", p_layer3_5_bn3_weight: \"f32[1024]\", p_layer3_5_bn3_bias: \"f32[1024]\", p_layer4_0_conv1_weight: \"f32[512, 1024, 1, 1]\", p_layer4_0_bn1_weight: \"f32[512]\", p_layer4_0_bn1_bias: \"f32[512]\", p_layer4_0_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_0_bn2_weight: \"f32[512]\", p_layer4_0_bn2_bias: \"f32[512]\", p_layer4_0_conv3_weight: \"f32[2048, 512, 1, 1]\", p_layer4_0_bn3_weight: \"f32[2048]\", p_layer4_0_bn3_bias: \"f32[2048]\", p_layer4_0_downsample_0_weight: \"f32[2048, 1024, 1, 1]\", p_layer4_0_downsample_1_weight: \"f32[2048]\", p_layer4_0_downsample_1_bias: \"f32[2048]\", p_layer4_1_conv1_weight: \"f32[512, 2048, 1, 1]\", p_layer4_1_bn1_weight: \"f32[512]\", p_layer4_1_bn1_bias: \"f32[512]\", p_layer4_1_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_1_bn2_weight: \"f32[512]\", p_layer4_1_bn2_bias: \"f32[512]\", p_layer4_1_conv3_weight: \"f32[2048, 512, 1, 1]\", p_layer4_1_bn3_weight: \"f32[2048]\", p_layer4_1_bn3_bias: \"f32[2048]\", p_layer4_2_conv1_weight: \"f32[512, 2048, 1, 1]\", p_layer4_2_bn1_weight: \"f32[512]\", p_layer4_2_bn1_bias: \"f32[512]\", p_layer4_2_conv2_weight: \"f32[512, 512, 3, 3]\", p_layer4_2_bn2_weight: \"f32[512]\", p_layer4_2_bn2_bias: \"f32[512]\", p_layer4_2_conv3_weight: \"f32[2048, 512, 1, 1]\", p_layer4_2_bn3_weight: \"f32[2048]\", p_layer4_2_bn3_bias: \"f32[2048]\", p_fc_weight: \"f32[1000, 2048]\", p_fc_bias: \"f32[1000]\", b_bn1_running_mean: \"f32[64]\", b_bn1_running_var: \"f32[64]\", b_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn1_running_mean: \"f32[64]\", b_layer1_0_bn1_running_var: \"f32[64]\", b_layer1_0_bn1_num_batches_tracked: \"i64[]\", b_layer1_0_bn2_running_mean: \"f32[64]\", b_layer1_0_bn2_running_var: \"f32[64]\", b_layer1_0_bn2_num_batches_tracked: \"i64[]\", b_layer1_0_bn3_running_mean: \"f32[256]\", b_layer1_0_bn3_running_var: \"f32[256]\", b_layer1_0_bn3_num_batches_tracked: \"i64[]\", b_layer1_0_downsample_1_running_mean: \"f32[256]\", b_layer1_0_downsample_1_running_var: \"f32[256]\", b_layer1_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer1_1_bn1_running_mean: \"f32[64]\", b_layer1_1_bn1_running_var: \"f32[64]\", b_layer1_1_bn1_num_batches_tracked: \"i64[]\", b_layer1_1_bn2_running_mean: \"f32[64]\", b_layer1_1_bn2_running_var: \"f32[64]\", b_layer1_1_bn2_num_batches_tracked: \"i64[]\", b_layer1_1_bn3_running_mean: \"f32[256]\", b_layer1_1_bn3_running_var: \"f32[256]\", b_layer1_1_bn3_num_batches_tracked: \"i64[]\", b_layer1_2_bn1_running_mean: \"f32[64]\", b_layer1_2_bn1_running_var: \"f32[64]\", b_layer1_2_bn1_num_batches_tracked: \"i64[]\", b_layer1_2_bn2_running_mean: \"f32[64]\", b_layer1_2_bn2_running_var: \"f32[64]\", b_layer1_2_bn2_num_batches_tracked: \"i64[]\", b_layer1_2_bn3_running_mean: \"f32[256]\", b_layer1_2_bn3_running_var: \"f32[256]\", b_layer1_2_bn3_num_batches_tracked: \"i64[]\", b_layer2_0_bn1_running_mean: \"f32[128]\", b_layer2_0_bn1_running_var: \"f32[128]\", b_layer2_0_bn1_num_batches_tracked: \"i64[]\", b_layer2_0_bn2_running_mean: \"f32[128]\", b_layer2_0_bn2_running_var: \"f32[128]\", b_layer2_0_bn2_num_batches_tracked: \"i64[]\", b_layer2_0_bn3_running_mean: \"f32[512]\", b_layer2_0_bn3_running_var: \"f32[512]\", b_layer2_0_bn3_num_batches_tracked: \"i64[]\", b_layer2_0_downsample_1_running_mean: \"f32[512]\", b_layer2_0_downsample_1_running_var: \"f32[512]\", b_layer2_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer2_1_bn1_running_mean: \"f32[128]\", b_layer2_1_bn1_running_var: \"f32[128]\", b_layer2_1_bn1_num_batches_tracked: \"i64[]\", b_layer2_1_bn2_running_mean: \"f32[128]\", b_layer2_1_bn2_running_var: \"f32[128]\", b_layer2_1_bn2_num_batches_tracked: \"i64[]\", b_layer2_1_bn3_running_mean: \"f32[512]\", b_layer2_1_bn3_running_var: \"f32[512]\", b_layer2_1_bn3_num_batches_tracked: \"i64[]\", b_layer2_2_bn1_running_mean: \"f32[128]\", b_layer2_2_bn1_running_var: \"f32[128]\", b_layer2_2_bn1_num_batches_tracked: \"i64[]\", b_layer2_2_bn2_running_mean: \"f32[128]\", b_layer2_2_bn2_running_var: \"f32[128]\", b_layer2_2_bn2_num_batches_tracked: \"i64[]\", b_layer2_2_bn3_running_mean: \"f32[512]\", b_layer2_2_bn3_running_var: \"f32[512]\", b_layer2_2_bn3_num_batches_tracked: \"i64[]\", b_layer2_3_bn1_running_mean: \"f32[128]\", b_layer2_3_bn1_running_var: \"f32[128]\", b_layer2_3_bn1_num_batches_tracked: \"i64[]\", b_layer2_3_bn2_running_mean: \"f32[128]\", b_layer2_3_bn2_running_var: \"f32[128]\", b_layer2_3_bn2_num_batches_tracked: \"i64[]\", b_layer2_3_bn3_running_mean: \"f32[512]\", b_layer2_3_bn3_running_var: \"f32[512]\", b_layer2_3_bn3_num_batches_tracked: \"i64[]\", b_layer3_0_bn1_running_mean: \"f32[256]\", b_layer3_0_bn1_running_var: \"f32[256]\", b_layer3_0_bn1_num_batches_tracked: \"i64[]\", b_layer3_0_bn2_running_mean: \"f32[256]\", b_layer3_0_bn2_running_var: \"f32[256]\", b_layer3_0_bn2_num_batches_tracked: \"i64[]\", b_layer3_0_bn3_running_mean: \"f32[1024]\", b_layer3_0_bn3_running_var: \"f32[1024]\", b_layer3_0_bn3_num_batches_tracked: \"i64[]\", b_layer3_0_downsample_1_running_mean: \"f32[1024]\", b_layer3_0_downsample_1_running_var: \"f32[1024]\", b_layer3_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer3_1_bn1_running_mean: \"f32[256]\", b_layer3_1_bn1_running_var: \"f32[256]\", b_layer3_1_bn1_num_batches_tracked: \"i64[]\", b_layer3_1_bn2_running_mean: \"f32[256]\", b_layer3_1_bn2_running_var: \"f32[256]\", b_layer3_1_bn2_num_batches_tracked: \"i64[]\", b_layer3_1_bn3_running_mean: \"f32[1024]\", b_layer3_1_bn3_running_var: \"f32[1024]\", b_layer3_1_bn3_num_batches_tracked: \"i64[]\", b_layer3_2_bn1_running_mean: \"f32[256]\", b_layer3_2_bn1_running_var: \"f32[256]\", b_layer3_2_bn1_num_batches_tracked: \"i64[]\", b_layer3_2_bn2_running_mean: \"f32[256]\", b_layer3_2_bn2_running_var: \"f32[256]\", b_layer3_2_bn2_num_batches_tracked: \"i64[]\", b_layer3_2_bn3_running_mean: \"f32[1024]\", b_layer3_2_bn3_running_var: \"f32[1024]\", b_layer3_2_bn3_num_batches_tracked: \"i64[]\", b_layer3_3_bn1_running_mean: \"f32[256]\", b_layer3_3_bn1_running_var: \"f32[256]\", b_layer3_3_bn1_num_batches_tracked: \"i64[]\", b_layer3_3_bn2_running_mean: \"f32[256]\", b_layer3_3_bn2_running_var: \"f32[256]\", b_layer3_3_bn2_num_batches_tracked: \"i64[]\", b_layer3_3_bn3_running_mean: \"f32[1024]\", b_layer3_3_bn3_running_var: \"f32[1024]\", b_layer3_3_bn3_num_batches_tracked: \"i64[]\", b_layer3_4_bn1_running_mean: \"f32[256]\", b_layer3_4_bn1_running_var: \"f32[256]\", b_layer3_4_bn1_num_batches_tracked: \"i64[]\", b_layer3_4_bn2_running_mean: \"f32[256]\", b_layer3_4_bn2_running_var: \"f32[256]\", b_layer3_4_bn2_num_batches_tracked: \"i64[]\", b_layer3_4_bn3_running_mean: \"f32[1024]\", b_layer3_4_bn3_running_var: \"f32[1024]\", b_layer3_4_bn3_num_batches_tracked: \"i64[]\", b_layer3_5_bn1_running_mean: \"f32[256]\", b_layer3_5_bn1_running_var: \"f32[256]\", b_layer3_5_bn1_num_batches_tracked: \"i64[]\", b_layer3_5_bn2_running_mean: \"f32[256]\", b_layer3_5_bn2_running_var: \"f32[256]\", b_layer3_5_bn2_num_batches_tracked: \"i64[]\", b_layer3_5_bn3_running_mean: \"f32[1024]\", b_layer3_5_bn3_running_var: \"f32[1024]\", b_layer3_5_bn3_num_batches_tracked: \"i64[]\", b_layer4_0_bn1_running_mean: \"f32[512]\", b_layer4_0_bn1_running_var: \"f32[512]\", b_layer4_0_bn1_num_batches_tracked: \"i64[]\", b_layer4_0_bn2_running_mean: \"f32[512]\", b_layer4_0_bn2_running_var: \"f32[512]\", b_layer4_0_bn2_num_batches_tracked: \"i64[]\", b_layer4_0_bn3_running_mean: \"f32[2048]\", b_layer4_0_bn3_running_var: \"f32[2048]\", b_layer4_0_bn3_num_batches_tracked: \"i64[]\", b_layer4_0_downsample_1_running_mean: \"f32[2048]\", b_layer4_0_downsample_1_running_var: \"f32[2048]\", b_layer4_0_downsample_1_num_batches_tracked: \"i64[]\", b_layer4_1_bn1_running_mean: \"f32[512]\", b_layer4_1_bn1_running_var: \"f32[512]\", b_layer4_1_bn1_num_batches_tracked: \"i64[]\", b_layer4_1_bn2_running_mean: \"f32[512]\", b_layer4_1_bn2_running_var: \"f32[512]\", b_layer4_1_bn2_num_batches_tracked: \"i64[]\", b_layer4_1_bn3_running_mean: \"f32[2048]\", b_layer4_1_bn3_running_var: \"f32[2048]\", b_layer4_1_bn3_num_batches_tracked: \"i64[]\", b_layer4_2_bn1_running_mean: \"f32[512]\", b_layer4_2_bn1_running_var: \"f32[512]\", b_layer4_2_bn1_num_batches_tracked: \"i64[]\", b_layer4_2_bn2_running_mean: \"f32[512]\", b_layer4_2_bn2_running_var: \"f32[512]\", b_layer4_2_bn2_num_batches_tracked: \"i64[]\", b_layer4_2_bn3_running_mean: \"f32[2048]\", b_layer4_2_bn3_running_var: \"f32[2048]\", b_layer4_2_bn3_num_batches_tracked: \"i64[]\", x: \"f32[1, 3, 224, 224]\"):\n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d: \"f32[1, 64, 112, 112]\" = torch.ops.aten.conv2d.default(x, p_conv1_weight, None, [2, 2], [3, 3]);  x = p_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_bn1_weight, p_bn1_bias, b_bn1_running_mean, b_bn1_running_var, 0.1, 1e-05);  conv2d = p_bn1_weight = p_bn1_bias = b_bn1_running_mean = b_bn1_running_var = None\n",
              "                    getitem: \"f32[1, 64, 112, 112]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu: \"f32[1, 64, 112, 112]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/pooling.py:226 in forward, code: return F.max_pool2d(\n",
              "                    max_pool2d: \"f32[1, 64, 56, 56]\" = torch.ops.aten.max_pool2d.default(relu, [3, 3], [2, 2], [1, 1]);  relu = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(max_pool2d, p_layer1_0_conv1_weight);  p_layer1_0_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_layer1_0_bn1_weight, p_layer1_0_bn1_bias, b_layer1_0_bn1_running_mean, b_layer1_0_bn1_running_var, 0.1, 1e-05);  conv2d_1 = p_layer1_0_bn1_weight = p_layer1_0_bn1_bias = b_layer1_0_bn1_running_mean = b_layer1_0_bn1_running_var = None\n",
              "                    getitem_3: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_1: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_2: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_1, p_layer1_0_conv2_weight, None, [1, 1], [1, 1]);  relu_1 = p_layer1_0_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_layer1_0_bn2_weight, p_layer1_0_bn2_bias, b_layer1_0_bn2_running_mean, b_layer1_0_bn2_running_var, 0.1, 1e-05);  conv2d_2 = p_layer1_0_bn2_weight = p_layer1_0_bn2_bias = b_layer1_0_bn2_running_mean = b_layer1_0_bn2_running_var = None\n",
              "                    getitem_6: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_2: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_6);  getitem_6 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_3: \"f32[1, 256, 56, 56]\" = torch.ops.aten.conv2d.default(relu_2, p_layer1_0_conv3_weight);  relu_2 = p_layer1_0_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_layer1_0_bn3_weight, p_layer1_0_bn3_bias, b_layer1_0_bn3_running_mean, b_layer1_0_bn3_running_var, 0.1, 1e-05);  conv2d_3 = p_layer1_0_bn3_weight = p_layer1_0_bn3_bias = b_layer1_0_bn3_running_mean = b_layer1_0_bn3_running_var = None\n",
              "                    getitem_9: \"f32[1, 256, 56, 56]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_4: \"f32[1, 256, 56, 56]\" = torch.ops.aten.conv2d.default(max_pool2d, p_layer1_0_downsample_0_weight);  max_pool2d = p_layer1_0_downsample_0_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_layer1_0_downsample_1_weight, p_layer1_0_downsample_1_bias, b_layer1_0_downsample_1_running_mean, b_layer1_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_4 = p_layer1_0_downsample_1_weight = p_layer1_0_downsample_1_bias = b_layer1_0_downsample_1_running_mean = b_layer1_0_downsample_1_running_var = None\n",
              "                    getitem_12: \"f32[1, 256, 56, 56]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add: \"f32[1, 256, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_9, getitem_12);  getitem_9 = getitem_12 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_3: \"f32[1, 256, 56, 56]\" = torch.ops.aten.relu.default(add);  add = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_5: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_3, p_layer1_1_conv1_weight);  p_layer1_1_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_layer1_1_bn1_weight, p_layer1_1_bn1_bias, b_layer1_1_bn1_running_mean, b_layer1_1_bn1_running_var, 0.1, 1e-05);  conv2d_5 = p_layer1_1_bn1_weight = p_layer1_1_bn1_bias = b_layer1_1_bn1_running_mean = b_layer1_1_bn1_running_var = None\n",
              "                    getitem_15: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_4: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_6: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_4, p_layer1_1_conv2_weight, None, [1, 1], [1, 1]);  relu_4 = p_layer1_1_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_layer1_1_bn2_weight, p_layer1_1_bn2_bias, b_layer1_1_bn2_running_mean, b_layer1_1_bn2_running_var, 0.1, 1e-05);  conv2d_6 = p_layer1_1_bn2_weight = p_layer1_1_bn2_bias = b_layer1_1_bn2_running_mean = b_layer1_1_bn2_running_var = None\n",
              "                    getitem_18: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_5: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_18);  getitem_18 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_7: \"f32[1, 256, 56, 56]\" = torch.ops.aten.conv2d.default(relu_5, p_layer1_1_conv3_weight);  relu_5 = p_layer1_1_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_layer1_1_bn3_weight, p_layer1_1_bn3_bias, b_layer1_1_bn3_running_mean, b_layer1_1_bn3_running_var, 0.1, 1e-05);  conv2d_7 = p_layer1_1_bn3_weight = p_layer1_1_bn3_bias = b_layer1_1_bn3_running_mean = b_layer1_1_bn3_running_var = None\n",
              "                    getitem_21: \"f32[1, 256, 56, 56]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_1: \"f32[1, 256, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_21, relu_3);  getitem_21 = relu_3 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_6: \"f32[1, 256, 56, 56]\" = torch.ops.aten.relu.default(add_1);  add_1 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_8: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_6, p_layer1_2_conv1_weight);  p_layer1_2_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_layer1_2_bn1_weight, p_layer1_2_bn1_bias, b_layer1_2_bn1_running_mean, b_layer1_2_bn1_running_var, 0.1, 1e-05);  conv2d_8 = p_layer1_2_bn1_weight = p_layer1_2_bn1_bias = b_layer1_2_bn1_running_mean = b_layer1_2_bn1_running_var = None\n",
              "                    getitem_24: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_7: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_24);  getitem_24 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_9: \"f32[1, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_7, p_layer1_2_conv2_weight, None, [1, 1], [1, 1]);  relu_7 = p_layer1_2_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_layer1_2_bn2_weight, p_layer1_2_bn2_bias, b_layer1_2_bn2_running_mean, b_layer1_2_bn2_running_var, 0.1, 1e-05);  conv2d_9 = p_layer1_2_bn2_weight = p_layer1_2_bn2_bias = b_layer1_2_bn2_running_mean = b_layer1_2_bn2_running_var = None\n",
              "                    getitem_27: \"f32[1, 64, 56, 56]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_8: \"f32[1, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_27);  getitem_27 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_10: \"f32[1, 256, 56, 56]\" = torch.ops.aten.conv2d.default(relu_8, p_layer1_2_conv3_weight);  relu_8 = p_layer1_2_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_layer1_2_bn3_weight, p_layer1_2_bn3_bias, b_layer1_2_bn3_running_mean, b_layer1_2_bn3_running_var, 0.1, 1e-05);  conv2d_10 = p_layer1_2_bn3_weight = p_layer1_2_bn3_bias = b_layer1_2_bn3_running_mean = b_layer1_2_bn3_running_var = None\n",
              "                    getitem_30: \"f32[1, 256, 56, 56]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_2: \"f32[1, 256, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_30, relu_6);  getitem_30 = relu_6 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_9: \"f32[1, 256, 56, 56]\" = torch.ops.aten.relu.default(add_2);  add_2 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_11: \"f32[1, 128, 56, 56]\" = torch.ops.aten.conv2d.default(relu_9, p_layer2_0_conv1_weight);  p_layer2_0_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_layer2_0_bn1_weight, p_layer2_0_bn1_bias, b_layer2_0_bn1_running_mean, b_layer2_0_bn1_running_var, 0.1, 1e-05);  conv2d_11 = p_layer2_0_bn1_weight = p_layer2_0_bn1_bias = b_layer2_0_bn1_running_mean = b_layer2_0_bn1_running_var = None\n",
              "                    getitem_33: \"f32[1, 128, 56, 56]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_10: \"f32[1, 128, 56, 56]\" = torch.ops.aten.relu.default(getitem_33);  getitem_33 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_12: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_10, p_layer2_0_conv2_weight, None, [2, 2], [1, 1]);  relu_10 = p_layer2_0_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_layer2_0_bn2_weight, p_layer2_0_bn2_bias, b_layer2_0_bn2_running_mean, b_layer2_0_bn2_running_var, 0.1, 1e-05);  conv2d_12 = p_layer2_0_bn2_weight = p_layer2_0_bn2_bias = b_layer2_0_bn2_running_mean = b_layer2_0_bn2_running_var = None\n",
              "                    getitem_36: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_11: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_36);  getitem_36 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_13: \"f32[1, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_11, p_layer2_0_conv3_weight);  relu_11 = p_layer2_0_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_layer2_0_bn3_weight, p_layer2_0_bn3_bias, b_layer2_0_bn3_running_mean, b_layer2_0_bn3_running_var, 0.1, 1e-05);  conv2d_13 = p_layer2_0_bn3_weight = p_layer2_0_bn3_bias = b_layer2_0_bn3_running_mean = b_layer2_0_bn3_running_var = None\n",
              "                    getitem_39: \"f32[1, 512, 28, 28]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_14: \"f32[1, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_9, p_layer2_0_downsample_0_weight, None, [2, 2]);  relu_9 = p_layer2_0_downsample_0_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_layer2_0_downsample_1_weight, p_layer2_0_downsample_1_bias, b_layer2_0_downsample_1_running_mean, b_layer2_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_14 = p_layer2_0_downsample_1_weight = p_layer2_0_downsample_1_bias = b_layer2_0_downsample_1_running_mean = b_layer2_0_downsample_1_running_var = None\n",
              "                    getitem_42: \"f32[1, 512, 28, 28]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_3: \"f32[1, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_39, getitem_42);  getitem_39 = getitem_42 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_12: \"f32[1, 512, 28, 28]\" = torch.ops.aten.relu.default(add_3);  add_3 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_15: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_12, p_layer2_1_conv1_weight);  p_layer2_1_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_15, p_layer2_1_bn1_weight, p_layer2_1_bn1_bias, b_layer2_1_bn1_running_mean, b_layer2_1_bn1_running_var, 0.1, 1e-05);  conv2d_15 = p_layer2_1_bn1_weight = p_layer2_1_bn1_bias = b_layer2_1_bn1_running_mean = b_layer2_1_bn1_running_var = None\n",
              "                    getitem_45: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_13: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_45);  getitem_45 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_16: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_13, p_layer2_1_conv2_weight, None, [1, 1], [1, 1]);  relu_13 = p_layer2_1_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, p_layer2_1_bn2_weight, p_layer2_1_bn2_bias, b_layer2_1_bn2_running_mean, b_layer2_1_bn2_running_var, 0.1, 1e-05);  conv2d_16 = p_layer2_1_bn2_weight = p_layer2_1_bn2_bias = b_layer2_1_bn2_running_mean = b_layer2_1_bn2_running_var = None\n",
              "                    getitem_48: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_14: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_48);  getitem_48 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_17: \"f32[1, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_14, p_layer2_1_conv3_weight);  relu_14 = p_layer2_1_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_17, p_layer2_1_bn3_weight, p_layer2_1_bn3_bias, b_layer2_1_bn3_running_mean, b_layer2_1_bn3_running_var, 0.1, 1e-05);  conv2d_17 = p_layer2_1_bn3_weight = p_layer2_1_bn3_bias = b_layer2_1_bn3_running_mean = b_layer2_1_bn3_running_var = None\n",
              "                    getitem_51: \"f32[1, 512, 28, 28]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_4: \"f32[1, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_51, relu_12);  getitem_51 = relu_12 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_15: \"f32[1, 512, 28, 28]\" = torch.ops.aten.relu.default(add_4);  add_4 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_18: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_15, p_layer2_2_conv1_weight);  p_layer2_2_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_layer2_2_bn1_weight, p_layer2_2_bn1_bias, b_layer2_2_bn1_running_mean, b_layer2_2_bn1_running_var, 0.1, 1e-05);  conv2d_18 = p_layer2_2_bn1_weight = p_layer2_2_bn1_bias = b_layer2_2_bn1_running_mean = b_layer2_2_bn1_running_var = None\n",
              "                    getitem_54: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_16: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_54);  getitem_54 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_19: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_16, p_layer2_2_conv2_weight, None, [1, 1], [1, 1]);  relu_16 = p_layer2_2_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_19, p_layer2_2_bn2_weight, p_layer2_2_bn2_bias, b_layer2_2_bn2_running_mean, b_layer2_2_bn2_running_var, 0.1, 1e-05);  conv2d_19 = p_layer2_2_bn2_weight = p_layer2_2_bn2_bias = b_layer2_2_bn2_running_mean = b_layer2_2_bn2_running_var = None\n",
              "                    getitem_57: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_17: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_57);  getitem_57 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_20: \"f32[1, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_17, p_layer2_2_conv3_weight);  relu_17 = p_layer2_2_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_20, p_layer2_2_bn3_weight, p_layer2_2_bn3_bias, b_layer2_2_bn3_running_mean, b_layer2_2_bn3_running_var, 0.1, 1e-05);  conv2d_20 = p_layer2_2_bn3_weight = p_layer2_2_bn3_bias = b_layer2_2_bn3_running_mean = b_layer2_2_bn3_running_var = None\n",
              "                    getitem_60: \"f32[1, 512, 28, 28]\" = _native_batch_norm_legit_no_training_20[0];  _native_batch_norm_legit_no_training_20 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_5: \"f32[1, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_60, relu_15);  getitem_60 = relu_15 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_18: \"f32[1, 512, 28, 28]\" = torch.ops.aten.relu.default(add_5);  add_5 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_21: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_18, p_layer2_3_conv1_weight);  p_layer2_3_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_21 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_21, p_layer2_3_bn1_weight, p_layer2_3_bn1_bias, b_layer2_3_bn1_running_mean, b_layer2_3_bn1_running_var, 0.1, 1e-05);  conv2d_21 = p_layer2_3_bn1_weight = p_layer2_3_bn1_bias = b_layer2_3_bn1_running_mean = b_layer2_3_bn1_running_var = None\n",
              "                    getitem_63: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_21[0];  _native_batch_norm_legit_no_training_21 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_19: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_63);  getitem_63 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_22: \"f32[1, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_19, p_layer2_3_conv2_weight, None, [1, 1], [1, 1]);  relu_19 = p_layer2_3_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_22 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_22, p_layer2_3_bn2_weight, p_layer2_3_bn2_bias, b_layer2_3_bn2_running_mean, b_layer2_3_bn2_running_var, 0.1, 1e-05);  conv2d_22 = p_layer2_3_bn2_weight = p_layer2_3_bn2_bias = b_layer2_3_bn2_running_mean = b_layer2_3_bn2_running_var = None\n",
              "                    getitem_66: \"f32[1, 128, 28, 28]\" = _native_batch_norm_legit_no_training_22[0];  _native_batch_norm_legit_no_training_22 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_20: \"f32[1, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_66);  getitem_66 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_23: \"f32[1, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_20, p_layer2_3_conv3_weight);  relu_20 = p_layer2_3_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_23 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_23, p_layer2_3_bn3_weight, p_layer2_3_bn3_bias, b_layer2_3_bn3_running_mean, b_layer2_3_bn3_running_var, 0.1, 1e-05);  conv2d_23 = p_layer2_3_bn3_weight = p_layer2_3_bn3_bias = b_layer2_3_bn3_running_mean = b_layer2_3_bn3_running_var = None\n",
              "                    getitem_69: \"f32[1, 512, 28, 28]\" = _native_batch_norm_legit_no_training_23[0];  _native_batch_norm_legit_no_training_23 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_6: \"f32[1, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_69, relu_18);  getitem_69 = relu_18 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_21: \"f32[1, 512, 28, 28]\" = torch.ops.aten.relu.default(add_6);  add_6 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_24: \"f32[1, 256, 28, 28]\" = torch.ops.aten.conv2d.default(relu_21, p_layer3_0_conv1_weight);  p_layer3_0_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_24 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_24, p_layer3_0_bn1_weight, p_layer3_0_bn1_bias, b_layer3_0_bn1_running_mean, b_layer3_0_bn1_running_var, 0.1, 1e-05);  conv2d_24 = p_layer3_0_bn1_weight = p_layer3_0_bn1_bias = b_layer3_0_bn1_running_mean = b_layer3_0_bn1_running_var = None\n",
              "                    getitem_72: \"f32[1, 256, 28, 28]\" = _native_batch_norm_legit_no_training_24[0];  _native_batch_norm_legit_no_training_24 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_22: \"f32[1, 256, 28, 28]\" = torch.ops.aten.relu.default(getitem_72);  getitem_72 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_25: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_22, p_layer3_0_conv2_weight, None, [2, 2], [1, 1]);  relu_22 = p_layer3_0_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_25 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_25, p_layer3_0_bn2_weight, p_layer3_0_bn2_bias, b_layer3_0_bn2_running_mean, b_layer3_0_bn2_running_var, 0.1, 1e-05);  conv2d_25 = p_layer3_0_bn2_weight = p_layer3_0_bn2_bias = b_layer3_0_bn2_running_mean = b_layer3_0_bn2_running_var = None\n",
              "                    getitem_75: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_25[0];  _native_batch_norm_legit_no_training_25 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_23: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_75);  getitem_75 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_26: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_23, p_layer3_0_conv3_weight);  relu_23 = p_layer3_0_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_26 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_26, p_layer3_0_bn3_weight, p_layer3_0_bn3_bias, b_layer3_0_bn3_running_mean, b_layer3_0_bn3_running_var, 0.1, 1e-05);  conv2d_26 = p_layer3_0_bn3_weight = p_layer3_0_bn3_bias = b_layer3_0_bn3_running_mean = b_layer3_0_bn3_running_var = None\n",
              "                    getitem_78: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_26[0];  _native_batch_norm_legit_no_training_26 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_27: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_21, p_layer3_0_downsample_0_weight, None, [2, 2]);  relu_21 = p_layer3_0_downsample_0_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_27 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_27, p_layer3_0_downsample_1_weight, p_layer3_0_downsample_1_bias, b_layer3_0_downsample_1_running_mean, b_layer3_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_27 = p_layer3_0_downsample_1_weight = p_layer3_0_downsample_1_bias = b_layer3_0_downsample_1_running_mean = b_layer3_0_downsample_1_running_var = None\n",
              "                    getitem_81: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_27[0];  _native_batch_norm_legit_no_training_27 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_7: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_78, getitem_81);  getitem_78 = getitem_81 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_24: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_7);  add_7 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_28: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_24, p_layer3_1_conv1_weight);  p_layer3_1_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_28 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_28, p_layer3_1_bn1_weight, p_layer3_1_bn1_bias, b_layer3_1_bn1_running_mean, b_layer3_1_bn1_running_var, 0.1, 1e-05);  conv2d_28 = p_layer3_1_bn1_weight = p_layer3_1_bn1_bias = b_layer3_1_bn1_running_mean = b_layer3_1_bn1_running_var = None\n",
              "                    getitem_84: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_28[0];  _native_batch_norm_legit_no_training_28 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_25: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_84);  getitem_84 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_29: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_25, p_layer3_1_conv2_weight, None, [1, 1], [1, 1]);  relu_25 = p_layer3_1_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_29 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_29, p_layer3_1_bn2_weight, p_layer3_1_bn2_bias, b_layer3_1_bn2_running_mean, b_layer3_1_bn2_running_var, 0.1, 1e-05);  conv2d_29 = p_layer3_1_bn2_weight = p_layer3_1_bn2_bias = b_layer3_1_bn2_running_mean = b_layer3_1_bn2_running_var = None\n",
              "                    getitem_87: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_29[0];  _native_batch_norm_legit_no_training_29 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_26: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_87);  getitem_87 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_30: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_26, p_layer3_1_conv3_weight);  relu_26 = p_layer3_1_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_30 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_30, p_layer3_1_bn3_weight, p_layer3_1_bn3_bias, b_layer3_1_bn3_running_mean, b_layer3_1_bn3_running_var, 0.1, 1e-05);  conv2d_30 = p_layer3_1_bn3_weight = p_layer3_1_bn3_bias = b_layer3_1_bn3_running_mean = b_layer3_1_bn3_running_var = None\n",
              "                    getitem_90: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_30[0];  _native_batch_norm_legit_no_training_30 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_8: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_90, relu_24);  getitem_90 = relu_24 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_27: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_8);  add_8 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_31: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_27, p_layer3_2_conv1_weight);  p_layer3_2_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_31 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_31, p_layer3_2_bn1_weight, p_layer3_2_bn1_bias, b_layer3_2_bn1_running_mean, b_layer3_2_bn1_running_var, 0.1, 1e-05);  conv2d_31 = p_layer3_2_bn1_weight = p_layer3_2_bn1_bias = b_layer3_2_bn1_running_mean = b_layer3_2_bn1_running_var = None\n",
              "                    getitem_93: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_31[0];  _native_batch_norm_legit_no_training_31 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_28: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_93);  getitem_93 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_32: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_28, p_layer3_2_conv2_weight, None, [1, 1], [1, 1]);  relu_28 = p_layer3_2_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_32 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_32, p_layer3_2_bn2_weight, p_layer3_2_bn2_bias, b_layer3_2_bn2_running_mean, b_layer3_2_bn2_running_var, 0.1, 1e-05);  conv2d_32 = p_layer3_2_bn2_weight = p_layer3_2_bn2_bias = b_layer3_2_bn2_running_mean = b_layer3_2_bn2_running_var = None\n",
              "                    getitem_96: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_32[0];  _native_batch_norm_legit_no_training_32 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_29: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_96);  getitem_96 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_33: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_29, p_layer3_2_conv3_weight);  relu_29 = p_layer3_2_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_33 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_33, p_layer3_2_bn3_weight, p_layer3_2_bn3_bias, b_layer3_2_bn3_running_mean, b_layer3_2_bn3_running_var, 0.1, 1e-05);  conv2d_33 = p_layer3_2_bn3_weight = p_layer3_2_bn3_bias = b_layer3_2_bn3_running_mean = b_layer3_2_bn3_running_var = None\n",
              "                    getitem_99: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_33[0];  _native_batch_norm_legit_no_training_33 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_9: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_99, relu_27);  getitem_99 = relu_27 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_30: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_9);  add_9 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_34: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_30, p_layer3_3_conv1_weight);  p_layer3_3_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_34 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_34, p_layer3_3_bn1_weight, p_layer3_3_bn1_bias, b_layer3_3_bn1_running_mean, b_layer3_3_bn1_running_var, 0.1, 1e-05);  conv2d_34 = p_layer3_3_bn1_weight = p_layer3_3_bn1_bias = b_layer3_3_bn1_running_mean = b_layer3_3_bn1_running_var = None\n",
              "                    getitem_102: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_34[0];  _native_batch_norm_legit_no_training_34 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_31: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_102);  getitem_102 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_35: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_31, p_layer3_3_conv2_weight, None, [1, 1], [1, 1]);  relu_31 = p_layer3_3_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_35 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_35, p_layer3_3_bn2_weight, p_layer3_3_bn2_bias, b_layer3_3_bn2_running_mean, b_layer3_3_bn2_running_var, 0.1, 1e-05);  conv2d_35 = p_layer3_3_bn2_weight = p_layer3_3_bn2_bias = b_layer3_3_bn2_running_mean = b_layer3_3_bn2_running_var = None\n",
              "                    getitem_105: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_35[0];  _native_batch_norm_legit_no_training_35 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_32: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_105);  getitem_105 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_36: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_32, p_layer3_3_conv3_weight);  relu_32 = p_layer3_3_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_36 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_36, p_layer3_3_bn3_weight, p_layer3_3_bn3_bias, b_layer3_3_bn3_running_mean, b_layer3_3_bn3_running_var, 0.1, 1e-05);  conv2d_36 = p_layer3_3_bn3_weight = p_layer3_3_bn3_bias = b_layer3_3_bn3_running_mean = b_layer3_3_bn3_running_var = None\n",
              "                    getitem_108: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_36[0];  _native_batch_norm_legit_no_training_36 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_10: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_108, relu_30);  getitem_108 = relu_30 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_33: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_10);  add_10 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_37: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_33, p_layer3_4_conv1_weight);  p_layer3_4_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_37 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_37, p_layer3_4_bn1_weight, p_layer3_4_bn1_bias, b_layer3_4_bn1_running_mean, b_layer3_4_bn1_running_var, 0.1, 1e-05);  conv2d_37 = p_layer3_4_bn1_weight = p_layer3_4_bn1_bias = b_layer3_4_bn1_running_mean = b_layer3_4_bn1_running_var = None\n",
              "                    getitem_111: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_37[0];  _native_batch_norm_legit_no_training_37 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_34: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_111);  getitem_111 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_38: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_34, p_layer3_4_conv2_weight, None, [1, 1], [1, 1]);  relu_34 = p_layer3_4_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_38 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_38, p_layer3_4_bn2_weight, p_layer3_4_bn2_bias, b_layer3_4_bn2_running_mean, b_layer3_4_bn2_running_var, 0.1, 1e-05);  conv2d_38 = p_layer3_4_bn2_weight = p_layer3_4_bn2_bias = b_layer3_4_bn2_running_mean = b_layer3_4_bn2_running_var = None\n",
              "                    getitem_114: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_38[0];  _native_batch_norm_legit_no_training_38 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_35: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_114);  getitem_114 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_39: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_35, p_layer3_4_conv3_weight);  relu_35 = p_layer3_4_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_39 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_39, p_layer3_4_bn3_weight, p_layer3_4_bn3_bias, b_layer3_4_bn3_running_mean, b_layer3_4_bn3_running_var, 0.1, 1e-05);  conv2d_39 = p_layer3_4_bn3_weight = p_layer3_4_bn3_bias = b_layer3_4_bn3_running_mean = b_layer3_4_bn3_running_var = None\n",
              "                    getitem_117: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_39[0];  _native_batch_norm_legit_no_training_39 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_11: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_117, relu_33);  getitem_117 = relu_33 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_36: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_11);  add_11 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_40: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_36, p_layer3_5_conv1_weight);  p_layer3_5_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_40 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_40, p_layer3_5_bn1_weight, p_layer3_5_bn1_bias, b_layer3_5_bn1_running_mean, b_layer3_5_bn1_running_var, 0.1, 1e-05);  conv2d_40 = p_layer3_5_bn1_weight = p_layer3_5_bn1_bias = b_layer3_5_bn1_running_mean = b_layer3_5_bn1_running_var = None\n",
              "                    getitem_120: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_40[0];  _native_batch_norm_legit_no_training_40 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_37: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_120);  getitem_120 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_41: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_37, p_layer3_5_conv2_weight, None, [1, 1], [1, 1]);  relu_37 = p_layer3_5_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_41 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_41, p_layer3_5_bn2_weight, p_layer3_5_bn2_bias, b_layer3_5_bn2_running_mean, b_layer3_5_bn2_running_var, 0.1, 1e-05);  conv2d_41 = p_layer3_5_bn2_weight = p_layer3_5_bn2_bias = b_layer3_5_bn2_running_mean = b_layer3_5_bn2_running_var = None\n",
              "                    getitem_123: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_41[0];  _native_batch_norm_legit_no_training_41 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_38: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_123);  getitem_123 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_42: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_38, p_layer3_5_conv3_weight);  relu_38 = p_layer3_5_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_42 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_42, p_layer3_5_bn3_weight, p_layer3_5_bn3_bias, b_layer3_5_bn3_running_mean, b_layer3_5_bn3_running_var, 0.1, 1e-05);  conv2d_42 = p_layer3_5_bn3_weight = p_layer3_5_bn3_bias = b_layer3_5_bn3_running_mean = b_layer3_5_bn3_running_var = None\n",
              "                    getitem_126: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_42[0];  _native_batch_norm_legit_no_training_42 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_12: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_126, relu_36);  getitem_126 = relu_36 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_39: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_12);  add_12 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_43: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(relu_39, p_layer4_0_conv1_weight);  p_layer4_0_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_43 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_43, p_layer4_0_bn1_weight, p_layer4_0_bn1_bias, b_layer4_0_bn1_running_mean, b_layer4_0_bn1_running_var, 0.1, 1e-05);  conv2d_43 = p_layer4_0_bn1_weight = p_layer4_0_bn1_bias = b_layer4_0_bn1_running_mean = b_layer4_0_bn1_running_var = None\n",
              "                    getitem_129: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_43[0];  _native_batch_norm_legit_no_training_43 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_40: \"f32[1, 512, 14, 14]\" = torch.ops.aten.relu.default(getitem_129);  getitem_129 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_44: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_40, p_layer4_0_conv2_weight, None, [2, 2], [1, 1]);  relu_40 = p_layer4_0_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_44 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_44, p_layer4_0_bn2_weight, p_layer4_0_bn2_bias, b_layer4_0_bn2_running_mean, b_layer4_0_bn2_running_var, 0.1, 1e-05);  conv2d_44 = p_layer4_0_bn2_weight = p_layer4_0_bn2_bias = b_layer4_0_bn2_running_mean = b_layer4_0_bn2_running_var = None\n",
              "                    getitem_132: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_44[0];  _native_batch_norm_legit_no_training_44 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_41: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_132);  getitem_132 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_45: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.conv2d.default(relu_41, p_layer4_0_conv3_weight);  relu_41 = p_layer4_0_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_45 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_45, p_layer4_0_bn3_weight, p_layer4_0_bn3_bias, b_layer4_0_bn3_running_mean, b_layer4_0_bn3_running_var, 0.1, 1e-05);  conv2d_45 = p_layer4_0_bn3_weight = p_layer4_0_bn3_bias = b_layer4_0_bn3_running_mean = b_layer4_0_bn3_running_var = None\n",
              "                    getitem_135: \"f32[1, 2048, 7, 7]\" = _native_batch_norm_legit_no_training_45[0];  _native_batch_norm_legit_no_training_45 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_46: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.conv2d.default(relu_39, p_layer4_0_downsample_0_weight, None, [2, 2]);  relu_39 = p_layer4_0_downsample_0_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_46 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_46, p_layer4_0_downsample_1_weight, p_layer4_0_downsample_1_bias, b_layer4_0_downsample_1_running_mean, b_layer4_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_46 = p_layer4_0_downsample_1_weight = p_layer4_0_downsample_1_bias = b_layer4_0_downsample_1_running_mean = b_layer4_0_downsample_1_running_var = None\n",
              "                    getitem_138: \"f32[1, 2048, 7, 7]\" = _native_batch_norm_legit_no_training_46[0];  _native_batch_norm_legit_no_training_46 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_13: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_135, getitem_138);  getitem_135 = getitem_138 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_42: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.relu.default(add_13);  add_13 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_47: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_42, p_layer4_1_conv1_weight);  p_layer4_1_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_47 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_47, p_layer4_1_bn1_weight, p_layer4_1_bn1_bias, b_layer4_1_bn1_running_mean, b_layer4_1_bn1_running_var, 0.1, 1e-05);  conv2d_47 = p_layer4_1_bn1_weight = p_layer4_1_bn1_bias = b_layer4_1_bn1_running_mean = b_layer4_1_bn1_running_var = None\n",
              "                    getitem_141: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_47[0];  _native_batch_norm_legit_no_training_47 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_43: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_141);  getitem_141 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_48: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_43, p_layer4_1_conv2_weight, None, [1, 1], [1, 1]);  relu_43 = p_layer4_1_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_48 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_48, p_layer4_1_bn2_weight, p_layer4_1_bn2_bias, b_layer4_1_bn2_running_mean, b_layer4_1_bn2_running_var, 0.1, 1e-05);  conv2d_48 = p_layer4_1_bn2_weight = p_layer4_1_bn2_bias = b_layer4_1_bn2_running_mean = b_layer4_1_bn2_running_var = None\n",
              "                    getitem_144: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_48[0];  _native_batch_norm_legit_no_training_48 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_44: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_144);  getitem_144 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_49: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.conv2d.default(relu_44, p_layer4_1_conv3_weight);  relu_44 = p_layer4_1_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_49 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_49, p_layer4_1_bn3_weight, p_layer4_1_bn3_bias, b_layer4_1_bn3_running_mean, b_layer4_1_bn3_running_var, 0.1, 1e-05);  conv2d_49 = p_layer4_1_bn3_weight = p_layer4_1_bn3_bias = b_layer4_1_bn3_running_mean = b_layer4_1_bn3_running_var = None\n",
              "                    getitem_147: \"f32[1, 2048, 7, 7]\" = _native_batch_norm_legit_no_training_49[0];  _native_batch_norm_legit_no_training_49 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_14: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_147, relu_42);  getitem_147 = relu_42 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_45: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.relu.default(add_14);  add_14 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_50: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_45, p_layer4_2_conv1_weight);  p_layer4_2_conv1_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_50 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_50, p_layer4_2_bn1_weight, p_layer4_2_bn1_bias, b_layer4_2_bn1_running_mean, b_layer4_2_bn1_running_var, 0.1, 1e-05);  conv2d_50 = p_layer4_2_bn1_weight = p_layer4_2_bn1_bias = b_layer4_2_bn1_running_mean = b_layer4_2_bn1_running_var = None\n",
              "                    getitem_150: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_50[0];  _native_batch_norm_legit_no_training_50 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_46: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_150);  getitem_150 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_51: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_46, p_layer4_2_conv2_weight, None, [1, 1], [1, 1]);  relu_46 = p_layer4_2_conv2_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_51 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_51, p_layer4_2_bn2_weight, p_layer4_2_bn2_bias, b_layer4_2_bn2_running_mean, b_layer4_2_bn2_running_var, 0.1, 1e-05);  conv2d_51 = p_layer4_2_bn2_weight = p_layer4_2_bn2_bias = b_layer4_2_bn2_running_mean = b_layer4_2_bn2_running_var = None\n",
              "                    getitem_153: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_51[0];  _native_batch_norm_legit_no_training_51 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_47: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_153);  getitem_153 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_52: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.conv2d.default(relu_47, p_layer4_2_conv3_weight);  relu_47 = p_layer4_2_conv3_weight = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
              "                    _native_batch_norm_legit_no_training_52 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_52, p_layer4_2_bn3_weight, p_layer4_2_bn3_bias, b_layer4_2_bn3_running_mean, b_layer4_2_bn3_running_var, 0.1, 1e-05);  conv2d_52 = p_layer4_2_bn3_weight = p_layer4_2_bn3_bias = b_layer4_2_bn3_running_mean = b_layer4_2_bn3_running_var = None\n",
              "                    getitem_156: \"f32[1, 2048, 7, 7]\" = _native_batch_norm_legit_no_training_52[0];  _native_batch_norm_legit_no_training_52 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:160 in forward, code: out += identity\n",
              "                    add_15: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_156, relu_45);  getitem_156 = relu_45 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
              "                    relu_48: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.relu.default(add_15);  add_15 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
              "                    mean: \"f32[1, 2048, 1, 1]\" = torch.ops.aten.mean.dim(relu_48, [-1, -2], True);  relu_48 = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torchvision/models/resnet.py:285 in forward, code: return self._forward_impl(x)\n",
              "                    view: \"f32[1, 2048]\" = torch.ops.aten.view.default(mean, [1, 2048]);  mean = None\n",
              "            \n",
              "                     # File: /home/mlops/miniconda3/envs/onnx-cpu/lib/python3.11/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear: \"f32[1, 1000]\" = torch.ops.aten.linear.default(view, p_fc_weight, p_fc_bias);  view = p_fc_weight = p_fc_bias = None\n",
              "                    return (linear,)\n",
              "            \n",
              "        Graph signature: \n",
              "            # inputs\n",
              "            p_conv1_weight: PARAMETER target='conv1.weight'\n",
              "            p_bn1_weight: PARAMETER target='bn1.weight'\n",
              "            p_bn1_bias: PARAMETER target='bn1.bias'\n",
              "            p_layer1_0_conv1_weight: PARAMETER target='layer1.0.conv1.weight'\n",
              "            p_layer1_0_bn1_weight: PARAMETER target='layer1.0.bn1.weight'\n",
              "            p_layer1_0_bn1_bias: PARAMETER target='layer1.0.bn1.bias'\n",
              "            p_layer1_0_conv2_weight: PARAMETER target='layer1.0.conv2.weight'\n",
              "            p_layer1_0_bn2_weight: PARAMETER target='layer1.0.bn2.weight'\n",
              "            p_layer1_0_bn2_bias: PARAMETER target='layer1.0.bn2.bias'\n",
              "            p_layer1_0_conv3_weight: PARAMETER target='layer1.0.conv3.weight'\n",
              "            p_layer1_0_bn3_weight: PARAMETER target='layer1.0.bn3.weight'\n",
              "            p_layer1_0_bn3_bias: PARAMETER target='layer1.0.bn3.bias'\n",
              "            p_layer1_0_downsample_0_weight: PARAMETER target='layer1.0.downsample.0.weight'\n",
              "            p_layer1_0_downsample_1_weight: PARAMETER target='layer1.0.downsample.1.weight'\n",
              "            p_layer1_0_downsample_1_bias: PARAMETER target='layer1.0.downsample.1.bias'\n",
              "            p_layer1_1_conv1_weight: PARAMETER target='layer1.1.conv1.weight'\n",
              "            p_layer1_1_bn1_weight: PARAMETER target='layer1.1.bn1.weight'\n",
              "            p_layer1_1_bn1_bias: PARAMETER target='layer1.1.bn1.bias'\n",
              "            p_layer1_1_conv2_weight: PARAMETER target='layer1.1.conv2.weight'\n",
              "            p_layer1_1_bn2_weight: PARAMETER target='layer1.1.bn2.weight'\n",
              "            p_layer1_1_bn2_bias: PARAMETER target='layer1.1.bn2.bias'\n",
              "            p_layer1_1_conv3_weight: PARAMETER target='layer1.1.conv3.weight'\n",
              "            p_layer1_1_bn3_weight: PARAMETER target='layer1.1.bn3.weight'\n",
              "            p_layer1_1_bn3_bias: PARAMETER target='layer1.1.bn3.bias'\n",
              "            p_layer1_2_conv1_weight: PARAMETER target='layer1.2.conv1.weight'\n",
              "            p_layer1_2_bn1_weight: PARAMETER target='layer1.2.bn1.weight'\n",
              "            p_layer1_2_bn1_bias: PARAMETER target='layer1.2.bn1.bias'\n",
              "            p_layer1_2_conv2_weight: PARAMETER target='layer1.2.conv2.weight'\n",
              "            p_layer1_2_bn2_weight: PARAMETER target='layer1.2.bn2.weight'\n",
              "            p_layer1_2_bn2_bias: PARAMETER target='layer1.2.bn2.bias'\n",
              "            p_layer1_2_conv3_weight: PARAMETER target='layer1.2.conv3.weight'\n",
              "            p_layer1_2_bn3_weight: PARAMETER target='layer1.2.bn3.weight'\n",
              "            p_layer1_2_bn3_bias: PARAMETER target='layer1.2.bn3.bias'\n",
              "            p_layer2_0_conv1_weight: PARAMETER target='layer2.0.conv1.weight'\n",
              "            p_layer2_0_bn1_weight: PARAMETER target='layer2.0.bn1.weight'\n",
              "            p_layer2_0_bn1_bias: PARAMETER target='layer2.0.bn1.bias'\n",
              "            p_layer2_0_conv2_weight: PARAMETER target='layer2.0.conv2.weight'\n",
              "            p_layer2_0_bn2_weight: PARAMETER target='layer2.0.bn2.weight'\n",
              "            p_layer2_0_bn2_bias: PARAMETER target='layer2.0.bn2.bias'\n",
              "            p_layer2_0_conv3_weight: PARAMETER target='layer2.0.conv3.weight'\n",
              "            p_layer2_0_bn3_weight: PARAMETER target='layer2.0.bn3.weight'\n",
              "            p_layer2_0_bn3_bias: PARAMETER target='layer2.0.bn3.bias'\n",
              "            p_layer2_0_downsample_0_weight: PARAMETER target='layer2.0.downsample.0.weight'\n",
              "            p_layer2_0_downsample_1_weight: PARAMETER target='layer2.0.downsample.1.weight'\n",
              "            p_layer2_0_downsample_1_bias: PARAMETER target='layer2.0.downsample.1.bias'\n",
              "            p_layer2_1_conv1_weight: PARAMETER target='layer2.1.conv1.weight'\n",
              "            p_layer2_1_bn1_weight: PARAMETER target='layer2.1.bn1.weight'\n",
              "            p_layer2_1_bn1_bias: PARAMETER target='layer2.1.bn1.bias'\n",
              "            p_layer2_1_conv2_weight: PARAMETER target='layer2.1.conv2.weight'\n",
              "            p_layer2_1_bn2_weight: PARAMETER target='layer2.1.bn2.weight'\n",
              "            p_layer2_1_bn2_bias: PARAMETER target='layer2.1.bn2.bias'\n",
              "            p_layer2_1_conv3_weight: PARAMETER target='layer2.1.conv3.weight'\n",
              "            p_layer2_1_bn3_weight: PARAMETER target='layer2.1.bn3.weight'\n",
              "            p_layer2_1_bn3_bias: PARAMETER target='layer2.1.bn3.bias'\n",
              "            p_layer2_2_conv1_weight: PARAMETER target='layer2.2.conv1.weight'\n",
              "            p_layer2_2_bn1_weight: PARAMETER target='layer2.2.bn1.weight'\n",
              "            p_layer2_2_bn1_bias: PARAMETER target='layer2.2.bn1.bias'\n",
              "            p_layer2_2_conv2_weight: PARAMETER target='layer2.2.conv2.weight'\n",
              "            p_layer2_2_bn2_weight: PARAMETER target='layer2.2.bn2.weight'\n",
              "            p_layer2_2_bn2_bias: PARAMETER target='layer2.2.bn2.bias'\n",
              "            p_layer2_2_conv3_weight: PARAMETER target='layer2.2.conv3.weight'\n",
              "            p_layer2_2_bn3_weight: PARAMETER target='layer2.2.bn3.weight'\n",
              "            p_layer2_2_bn3_bias: PARAMETER target='layer2.2.bn3.bias'\n",
              "            p_layer2_3_conv1_weight: PARAMETER target='layer2.3.conv1.weight'\n",
              "            p_layer2_3_bn1_weight: PARAMETER target='layer2.3.bn1.weight'\n",
              "            p_layer2_3_bn1_bias: PARAMETER target='layer2.3.bn1.bias'\n",
              "            p_layer2_3_conv2_weight: PARAMETER target='layer2.3.conv2.weight'\n",
              "            p_layer2_3_bn2_weight: PARAMETER target='layer2.3.bn2.weight'\n",
              "            p_layer2_3_bn2_bias: PARAMETER target='layer2.3.bn2.bias'\n",
              "            p_layer2_3_conv3_weight: PARAMETER target='layer2.3.conv3.weight'\n",
              "            p_layer2_3_bn3_weight: PARAMETER target='layer2.3.bn3.weight'\n",
              "            p_layer2_3_bn3_bias: PARAMETER target='layer2.3.bn3.bias'\n",
              "            p_layer3_0_conv1_weight: PARAMETER target='layer3.0.conv1.weight'\n",
              "            p_layer3_0_bn1_weight: PARAMETER target='layer3.0.bn1.weight'\n",
              "            p_layer3_0_bn1_bias: PARAMETER target='layer3.0.bn1.bias'\n",
              "            p_layer3_0_conv2_weight: PARAMETER target='layer3.0.conv2.weight'\n",
              "            p_layer3_0_bn2_weight: PARAMETER target='layer3.0.bn2.weight'\n",
              "            p_layer3_0_bn2_bias: PARAMETER target='layer3.0.bn2.bias'\n",
              "            p_layer3_0_conv3_weight: PARAMETER target='layer3.0.conv3.weight'\n",
              "            p_layer3_0_bn3_weight: PARAMETER target='layer3.0.bn3.weight'\n",
              "            p_layer3_0_bn3_bias: PARAMETER target='layer3.0.bn3.bias'\n",
              "            p_layer3_0_downsample_0_weight: PARAMETER target='layer3.0.downsample.0.weight'\n",
              "            p_layer3_0_downsample_1_weight: PARAMETER target='layer3.0.downsample.1.weight'\n",
              "            p_layer3_0_downsample_1_bias: PARAMETER target='layer3.0.downsample.1.bias'\n",
              "            p_layer3_1_conv1_weight: PARAMETER target='layer3.1.conv1.weight'\n",
              "            p_layer3_1_bn1_weight: PARAMETER target='layer3.1.bn1.weight'\n",
              "            p_layer3_1_bn1_bias: PARAMETER target='layer3.1.bn1.bias'\n",
              "            p_layer3_1_conv2_weight: PARAMETER target='layer3.1.conv2.weight'\n",
              "            p_layer3_1_bn2_weight: PARAMETER target='layer3.1.bn2.weight'\n",
              "            p_layer3_1_bn2_bias: PARAMETER target='layer3.1.bn2.bias'\n",
              "            p_layer3_1_conv3_weight: PARAMETER target='layer3.1.conv3.weight'\n",
              "            p_layer3_1_bn3_weight: PARAMETER target='layer3.1.bn3.weight'\n",
              "            p_layer3_1_bn3_bias: PARAMETER target='layer3.1.bn3.bias'\n",
              "            p_layer3_2_conv1_weight: PARAMETER target='layer3.2.conv1.weight'\n",
              "            p_layer3_2_bn1_weight: PARAMETER target='layer3.2.bn1.weight'\n",
              "            p_layer3_2_bn1_bias: PARAMETER target='layer3.2.bn1.bias'\n",
              "            p_layer3_2_conv2_weight: PARAMETER target='layer3.2.conv2.weight'\n",
              "            p_layer3_2_bn2_weight: PARAMETER target='layer3.2.bn2.weight'\n",
              "            p_layer3_2_bn2_bias: PARAMETER target='layer3.2.bn2.bias'\n",
              "            p_layer3_2_conv3_weight: PARAMETER target='layer3.2.conv3.weight'\n",
              "            p_layer3_2_bn3_weight: PARAMETER target='layer3.2.bn3.weight'\n",
              "            p_layer3_2_bn3_bias: PARAMETER target='layer3.2.bn3.bias'\n",
              "            p_layer3_3_conv1_weight: PARAMETER target='layer3.3.conv1.weight'\n",
              "            p_layer3_3_bn1_weight: PARAMETER target='layer3.3.bn1.weight'\n",
              "            p_layer3_3_bn1_bias: PARAMETER target='layer3.3.bn1.bias'\n",
              "            p_layer3_3_conv2_weight: PARAMETER target='layer3.3.conv2.weight'\n",
              "            p_layer3_3_bn2_weight: PARAMETER target='layer3.3.bn2.weight'\n",
              "            p_layer3_3_bn2_bias: PARAMETER target='layer3.3.bn2.bias'\n",
              "            p_layer3_3_conv3_weight: PARAMETER target='layer3.3.conv3.weight'\n",
              "            p_layer3_3_bn3_weight: PARAMETER target='layer3.3.bn3.weight'\n",
              "            p_layer3_3_bn3_bias: PARAMETER target='layer3.3.bn3.bias'\n",
              "            p_layer3_4_conv1_weight: PARAMETER target='layer3.4.conv1.weight'\n",
              "            p_layer3_4_bn1_weight: PARAMETER target='layer3.4.bn1.weight'\n",
              "            p_layer3_4_bn1_bias: PARAMETER target='layer3.4.bn1.bias'\n",
              "            p_layer3_4_conv2_weight: PARAMETER target='layer3.4.conv2.weight'\n",
              "            p_layer3_4_bn2_weight: PARAMETER target='layer3.4.bn2.weight'\n",
              "            p_layer3_4_bn2_bias: PARAMETER target='layer3.4.bn2.bias'\n",
              "            p_layer3_4_conv3_weight: PARAMETER target='layer3.4.conv3.weight'\n",
              "            p_layer3_4_bn3_weight: PARAMETER target='layer3.4.bn3.weight'\n",
              "            p_layer3_4_bn3_bias: PARAMETER target='layer3.4.bn3.bias'\n",
              "            p_layer3_5_conv1_weight: PARAMETER target='layer3.5.conv1.weight'\n",
              "            p_layer3_5_bn1_weight: PARAMETER target='layer3.5.bn1.weight'\n",
              "            p_layer3_5_bn1_bias: PARAMETER target='layer3.5.bn1.bias'\n",
              "            p_layer3_5_conv2_weight: PARAMETER target='layer3.5.conv2.weight'\n",
              "            p_layer3_5_bn2_weight: PARAMETER target='layer3.5.bn2.weight'\n",
              "            p_layer3_5_bn2_bias: PARAMETER target='layer3.5.bn2.bias'\n",
              "            p_layer3_5_conv3_weight: PARAMETER target='layer3.5.conv3.weight'\n",
              "            p_layer3_5_bn3_weight: PARAMETER target='layer3.5.bn3.weight'\n",
              "            p_layer3_5_bn3_bias: PARAMETER target='layer3.5.bn3.bias'\n",
              "            p_layer4_0_conv1_weight: PARAMETER target='layer4.0.conv1.weight'\n",
              "            p_layer4_0_bn1_weight: PARAMETER target='layer4.0.bn1.weight'\n",
              "            p_layer4_0_bn1_bias: PARAMETER target='layer4.0.bn1.bias'\n",
              "            p_layer4_0_conv2_weight: PARAMETER target='layer4.0.conv2.weight'\n",
              "            p_layer4_0_bn2_weight: PARAMETER target='layer4.0.bn2.weight'\n",
              "            p_layer4_0_bn2_bias: PARAMETER target='layer4.0.bn2.bias'\n",
              "            p_layer4_0_conv3_weight: PARAMETER target='layer4.0.conv3.weight'\n",
              "            p_layer4_0_bn3_weight: PARAMETER target='layer4.0.bn3.weight'\n",
              "            p_layer4_0_bn3_bias: PARAMETER target='layer4.0.bn3.bias'\n",
              "            p_layer4_0_downsample_0_weight: PARAMETER target='layer4.0.downsample.0.weight'\n",
              "            p_layer4_0_downsample_1_weight: PARAMETER target='layer4.0.downsample.1.weight'\n",
              "            p_layer4_0_downsample_1_bias: PARAMETER target='layer4.0.downsample.1.bias'\n",
              "            p_layer4_1_conv1_weight: PARAMETER target='layer4.1.conv1.weight'\n",
              "            p_layer4_1_bn1_weight: PARAMETER target='layer4.1.bn1.weight'\n",
              "            p_layer4_1_bn1_bias: PARAMETER target='layer4.1.bn1.bias'\n",
              "            p_layer4_1_conv2_weight: PARAMETER target='layer4.1.conv2.weight'\n",
              "            p_layer4_1_bn2_weight: PARAMETER target='layer4.1.bn2.weight'\n",
              "            p_layer4_1_bn2_bias: PARAMETER target='layer4.1.bn2.bias'\n",
              "            p_layer4_1_conv3_weight: PARAMETER target='layer4.1.conv3.weight'\n",
              "            p_layer4_1_bn3_weight: PARAMETER target='layer4.1.bn3.weight'\n",
              "            p_layer4_1_bn3_bias: PARAMETER target='layer4.1.bn3.bias'\n",
              "            p_layer4_2_conv1_weight: PARAMETER target='layer4.2.conv1.weight'\n",
              "            p_layer4_2_bn1_weight: PARAMETER target='layer4.2.bn1.weight'\n",
              "            p_layer4_2_bn1_bias: PARAMETER target='layer4.2.bn1.bias'\n",
              "            p_layer4_2_conv2_weight: PARAMETER target='layer4.2.conv2.weight'\n",
              "            p_layer4_2_bn2_weight: PARAMETER target='layer4.2.bn2.weight'\n",
              "            p_layer4_2_bn2_bias: PARAMETER target='layer4.2.bn2.bias'\n",
              "            p_layer4_2_conv3_weight: PARAMETER target='layer4.2.conv3.weight'\n",
              "            p_layer4_2_bn3_weight: PARAMETER target='layer4.2.bn3.weight'\n",
              "            p_layer4_2_bn3_bias: PARAMETER target='layer4.2.bn3.bias'\n",
              "            p_fc_weight: PARAMETER target='fc.weight'\n",
              "            p_fc_bias: PARAMETER target='fc.bias'\n",
              "            b_bn1_running_mean: BUFFER target='bn1.running_mean' persistent=True\n",
              "            b_bn1_running_var: BUFFER target='bn1.running_var' persistent=True\n",
              "            b_bn1_num_batches_tracked: BUFFER target='bn1.num_batches_tracked' persistent=True\n",
              "            b_layer1_0_bn1_running_mean: BUFFER target='layer1.0.bn1.running_mean' persistent=True\n",
              "            b_layer1_0_bn1_running_var: BUFFER target='layer1.0.bn1.running_var' persistent=True\n",
              "            b_layer1_0_bn1_num_batches_tracked: BUFFER target='layer1.0.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer1_0_bn2_running_mean: BUFFER target='layer1.0.bn2.running_mean' persistent=True\n",
              "            b_layer1_0_bn2_running_var: BUFFER target='layer1.0.bn2.running_var' persistent=True\n",
              "            b_layer1_0_bn2_num_batches_tracked: BUFFER target='layer1.0.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer1_0_bn3_running_mean: BUFFER target='layer1.0.bn3.running_mean' persistent=True\n",
              "            b_layer1_0_bn3_running_var: BUFFER target='layer1.0.bn3.running_var' persistent=True\n",
              "            b_layer1_0_bn3_num_batches_tracked: BUFFER target='layer1.0.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer1_0_downsample_1_running_mean: BUFFER target='layer1.0.downsample.1.running_mean' persistent=True\n",
              "            b_layer1_0_downsample_1_running_var: BUFFER target='layer1.0.downsample.1.running_var' persistent=True\n",
              "            b_layer1_0_downsample_1_num_batches_tracked: BUFFER target='layer1.0.downsample.1.num_batches_tracked' persistent=True\n",
              "            b_layer1_1_bn1_running_mean: BUFFER target='layer1.1.bn1.running_mean' persistent=True\n",
              "            b_layer1_1_bn1_running_var: BUFFER target='layer1.1.bn1.running_var' persistent=True\n",
              "            b_layer1_1_bn1_num_batches_tracked: BUFFER target='layer1.1.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer1_1_bn2_running_mean: BUFFER target='layer1.1.bn2.running_mean' persistent=True\n",
              "            b_layer1_1_bn2_running_var: BUFFER target='layer1.1.bn2.running_var' persistent=True\n",
              "            b_layer1_1_bn2_num_batches_tracked: BUFFER target='layer1.1.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer1_1_bn3_running_mean: BUFFER target='layer1.1.bn3.running_mean' persistent=True\n",
              "            b_layer1_1_bn3_running_var: BUFFER target='layer1.1.bn3.running_var' persistent=True\n",
              "            b_layer1_1_bn3_num_batches_tracked: BUFFER target='layer1.1.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer1_2_bn1_running_mean: BUFFER target='layer1.2.bn1.running_mean' persistent=True\n",
              "            b_layer1_2_bn1_running_var: BUFFER target='layer1.2.bn1.running_var' persistent=True\n",
              "            b_layer1_2_bn1_num_batches_tracked: BUFFER target='layer1.2.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer1_2_bn2_running_mean: BUFFER target='layer1.2.bn2.running_mean' persistent=True\n",
              "            b_layer1_2_bn2_running_var: BUFFER target='layer1.2.bn2.running_var' persistent=True\n",
              "            b_layer1_2_bn2_num_batches_tracked: BUFFER target='layer1.2.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer1_2_bn3_running_mean: BUFFER target='layer1.2.bn3.running_mean' persistent=True\n",
              "            b_layer1_2_bn3_running_var: BUFFER target='layer1.2.bn3.running_var' persistent=True\n",
              "            b_layer1_2_bn3_num_batches_tracked: BUFFER target='layer1.2.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer2_0_bn1_running_mean: BUFFER target='layer2.0.bn1.running_mean' persistent=True\n",
              "            b_layer2_0_bn1_running_var: BUFFER target='layer2.0.bn1.running_var' persistent=True\n",
              "            b_layer2_0_bn1_num_batches_tracked: BUFFER target='layer2.0.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer2_0_bn2_running_mean: BUFFER target='layer2.0.bn2.running_mean' persistent=True\n",
              "            b_layer2_0_bn2_running_var: BUFFER target='layer2.0.bn2.running_var' persistent=True\n",
              "            b_layer2_0_bn2_num_batches_tracked: BUFFER target='layer2.0.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer2_0_bn3_running_mean: BUFFER target='layer2.0.bn3.running_mean' persistent=True\n",
              "            b_layer2_0_bn3_running_var: BUFFER target='layer2.0.bn3.running_var' persistent=True\n",
              "            b_layer2_0_bn3_num_batches_tracked: BUFFER target='layer2.0.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer2_0_downsample_1_running_mean: BUFFER target='layer2.0.downsample.1.running_mean' persistent=True\n",
              "            b_layer2_0_downsample_1_running_var: BUFFER target='layer2.0.downsample.1.running_var' persistent=True\n",
              "            b_layer2_0_downsample_1_num_batches_tracked: BUFFER target='layer2.0.downsample.1.num_batches_tracked' persistent=True\n",
              "            b_layer2_1_bn1_running_mean: BUFFER target='layer2.1.bn1.running_mean' persistent=True\n",
              "            b_layer2_1_bn1_running_var: BUFFER target='layer2.1.bn1.running_var' persistent=True\n",
              "            b_layer2_1_bn1_num_batches_tracked: BUFFER target='layer2.1.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer2_1_bn2_running_mean: BUFFER target='layer2.1.bn2.running_mean' persistent=True\n",
              "            b_layer2_1_bn2_running_var: BUFFER target='layer2.1.bn2.running_var' persistent=True\n",
              "            b_layer2_1_bn2_num_batches_tracked: BUFFER target='layer2.1.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer2_1_bn3_running_mean: BUFFER target='layer2.1.bn3.running_mean' persistent=True\n",
              "            b_layer2_1_bn3_running_var: BUFFER target='layer2.1.bn3.running_var' persistent=True\n",
              "            b_layer2_1_bn3_num_batches_tracked: BUFFER target='layer2.1.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer2_2_bn1_running_mean: BUFFER target='layer2.2.bn1.running_mean' persistent=True\n",
              "            b_layer2_2_bn1_running_var: BUFFER target='layer2.2.bn1.running_var' persistent=True\n",
              "            b_layer2_2_bn1_num_batches_tracked: BUFFER target='layer2.2.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer2_2_bn2_running_mean: BUFFER target='layer2.2.bn2.running_mean' persistent=True\n",
              "            b_layer2_2_bn2_running_var: BUFFER target='layer2.2.bn2.running_var' persistent=True\n",
              "            b_layer2_2_bn2_num_batches_tracked: BUFFER target='layer2.2.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer2_2_bn3_running_mean: BUFFER target='layer2.2.bn3.running_mean' persistent=True\n",
              "            b_layer2_2_bn3_running_var: BUFFER target='layer2.2.bn3.running_var' persistent=True\n",
              "            b_layer2_2_bn3_num_batches_tracked: BUFFER target='layer2.2.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer2_3_bn1_running_mean: BUFFER target='layer2.3.bn1.running_mean' persistent=True\n",
              "            b_layer2_3_bn1_running_var: BUFFER target='layer2.3.bn1.running_var' persistent=True\n",
              "            b_layer2_3_bn1_num_batches_tracked: BUFFER target='layer2.3.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer2_3_bn2_running_mean: BUFFER target='layer2.3.bn2.running_mean' persistent=True\n",
              "            b_layer2_3_bn2_running_var: BUFFER target='layer2.3.bn2.running_var' persistent=True\n",
              "            b_layer2_3_bn2_num_batches_tracked: BUFFER target='layer2.3.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer2_3_bn3_running_mean: BUFFER target='layer2.3.bn3.running_mean' persistent=True\n",
              "            b_layer2_3_bn3_running_var: BUFFER target='layer2.3.bn3.running_var' persistent=True\n",
              "            b_layer2_3_bn3_num_batches_tracked: BUFFER target='layer2.3.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer3_0_bn1_running_mean: BUFFER target='layer3.0.bn1.running_mean' persistent=True\n",
              "            b_layer3_0_bn1_running_var: BUFFER target='layer3.0.bn1.running_var' persistent=True\n",
              "            b_layer3_0_bn1_num_batches_tracked: BUFFER target='layer3.0.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer3_0_bn2_running_mean: BUFFER target='layer3.0.bn2.running_mean' persistent=True\n",
              "            b_layer3_0_bn2_running_var: BUFFER target='layer3.0.bn2.running_var' persistent=True\n",
              "            b_layer3_0_bn2_num_batches_tracked: BUFFER target='layer3.0.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer3_0_bn3_running_mean: BUFFER target='layer3.0.bn3.running_mean' persistent=True\n",
              "            b_layer3_0_bn3_running_var: BUFFER target='layer3.0.bn3.running_var' persistent=True\n",
              "            b_layer3_0_bn3_num_batches_tracked: BUFFER target='layer3.0.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer3_0_downsample_1_running_mean: BUFFER target='layer3.0.downsample.1.running_mean' persistent=True\n",
              "            b_layer3_0_downsample_1_running_var: BUFFER target='layer3.0.downsample.1.running_var' persistent=True\n",
              "            b_layer3_0_downsample_1_num_batches_tracked: BUFFER target='layer3.0.downsample.1.num_batches_tracked' persistent=True\n",
              "            b_layer3_1_bn1_running_mean: BUFFER target='layer3.1.bn1.running_mean' persistent=True\n",
              "            b_layer3_1_bn1_running_var: BUFFER target='layer3.1.bn1.running_var' persistent=True\n",
              "            b_layer3_1_bn1_num_batches_tracked: BUFFER target='layer3.1.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer3_1_bn2_running_mean: BUFFER target='layer3.1.bn2.running_mean' persistent=True\n",
              "            b_layer3_1_bn2_running_var: BUFFER target='layer3.1.bn2.running_var' persistent=True\n",
              "            b_layer3_1_bn2_num_batches_tracked: BUFFER target='layer3.1.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer3_1_bn3_running_mean: BUFFER target='layer3.1.bn3.running_mean' persistent=True\n",
              "            b_layer3_1_bn3_running_var: BUFFER target='layer3.1.bn3.running_var' persistent=True\n",
              "            b_layer3_1_bn3_num_batches_tracked: BUFFER target='layer3.1.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer3_2_bn1_running_mean: BUFFER target='layer3.2.bn1.running_mean' persistent=True\n",
              "            b_layer3_2_bn1_running_var: BUFFER target='layer3.2.bn1.running_var' persistent=True\n",
              "            b_layer3_2_bn1_num_batches_tracked: BUFFER target='layer3.2.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer3_2_bn2_running_mean: BUFFER target='layer3.2.bn2.running_mean' persistent=True\n",
              "            b_layer3_2_bn2_running_var: BUFFER target='layer3.2.bn2.running_var' persistent=True\n",
              "            b_layer3_2_bn2_num_batches_tracked: BUFFER target='layer3.2.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer3_2_bn3_running_mean: BUFFER target='layer3.2.bn3.running_mean' persistent=True\n",
              "            b_layer3_2_bn3_running_var: BUFFER target='layer3.2.bn3.running_var' persistent=True\n",
              "            b_layer3_2_bn3_num_batches_tracked: BUFFER target='layer3.2.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer3_3_bn1_running_mean: BUFFER target='layer3.3.bn1.running_mean' persistent=True\n",
              "            b_layer3_3_bn1_running_var: BUFFER target='layer3.3.bn1.running_var' persistent=True\n",
              "            b_layer3_3_bn1_num_batches_tracked: BUFFER target='layer3.3.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer3_3_bn2_running_mean: BUFFER target='layer3.3.bn2.running_mean' persistent=True\n",
              "            b_layer3_3_bn2_running_var: BUFFER target='layer3.3.bn2.running_var' persistent=True\n",
              "            b_layer3_3_bn2_num_batches_tracked: BUFFER target='layer3.3.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer3_3_bn3_running_mean: BUFFER target='layer3.3.bn3.running_mean' persistent=True\n",
              "            b_layer3_3_bn3_running_var: BUFFER target='layer3.3.bn3.running_var' persistent=True\n",
              "            b_layer3_3_bn3_num_batches_tracked: BUFFER target='layer3.3.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer3_4_bn1_running_mean: BUFFER target='layer3.4.bn1.running_mean' persistent=True\n",
              "            b_layer3_4_bn1_running_var: BUFFER target='layer3.4.bn1.running_var' persistent=True\n",
              "            b_layer3_4_bn1_num_batches_tracked: BUFFER target='layer3.4.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer3_4_bn2_running_mean: BUFFER target='layer3.4.bn2.running_mean' persistent=True\n",
              "            b_layer3_4_bn2_running_var: BUFFER target='layer3.4.bn2.running_var' persistent=True\n",
              "            b_layer3_4_bn2_num_batches_tracked: BUFFER target='layer3.4.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer3_4_bn3_running_mean: BUFFER target='layer3.4.bn3.running_mean' persistent=True\n",
              "            b_layer3_4_bn3_running_var: BUFFER target='layer3.4.bn3.running_var' persistent=True\n",
              "            b_layer3_4_bn3_num_batches_tracked: BUFFER target='layer3.4.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer3_5_bn1_running_mean: BUFFER target='layer3.5.bn1.running_mean' persistent=True\n",
              "            b_layer3_5_bn1_running_var: BUFFER target='layer3.5.bn1.running_var' persistent=True\n",
              "            b_layer3_5_bn1_num_batches_tracked: BUFFER target='layer3.5.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer3_5_bn2_running_mean: BUFFER target='layer3.5.bn2.running_mean' persistent=True\n",
              "            b_layer3_5_bn2_running_var: BUFFER target='layer3.5.bn2.running_var' persistent=True\n",
              "            b_layer3_5_bn2_num_batches_tracked: BUFFER target='layer3.5.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer3_5_bn3_running_mean: BUFFER target='layer3.5.bn3.running_mean' persistent=True\n",
              "            b_layer3_5_bn3_running_var: BUFFER target='layer3.5.bn3.running_var' persistent=True\n",
              "            b_layer3_5_bn3_num_batches_tracked: BUFFER target='layer3.5.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer4_0_bn1_running_mean: BUFFER target='layer4.0.bn1.running_mean' persistent=True\n",
              "            b_layer4_0_bn1_running_var: BUFFER target='layer4.0.bn1.running_var' persistent=True\n",
              "            b_layer4_0_bn1_num_batches_tracked: BUFFER target='layer4.0.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer4_0_bn2_running_mean: BUFFER target='layer4.0.bn2.running_mean' persistent=True\n",
              "            b_layer4_0_bn2_running_var: BUFFER target='layer4.0.bn2.running_var' persistent=True\n",
              "            b_layer4_0_bn2_num_batches_tracked: BUFFER target='layer4.0.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer4_0_bn3_running_mean: BUFFER target='layer4.0.bn3.running_mean' persistent=True\n",
              "            b_layer4_0_bn3_running_var: BUFFER target='layer4.0.bn3.running_var' persistent=True\n",
              "            b_layer4_0_bn3_num_batches_tracked: BUFFER target='layer4.0.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer4_0_downsample_1_running_mean: BUFFER target='layer4.0.downsample.1.running_mean' persistent=True\n",
              "            b_layer4_0_downsample_1_running_var: BUFFER target='layer4.0.downsample.1.running_var' persistent=True\n",
              "            b_layer4_0_downsample_1_num_batches_tracked: BUFFER target='layer4.0.downsample.1.num_batches_tracked' persistent=True\n",
              "            b_layer4_1_bn1_running_mean: BUFFER target='layer4.1.bn1.running_mean' persistent=True\n",
              "            b_layer4_1_bn1_running_var: BUFFER target='layer4.1.bn1.running_var' persistent=True\n",
              "            b_layer4_1_bn1_num_batches_tracked: BUFFER target='layer4.1.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer4_1_bn2_running_mean: BUFFER target='layer4.1.bn2.running_mean' persistent=True\n",
              "            b_layer4_1_bn2_running_var: BUFFER target='layer4.1.bn2.running_var' persistent=True\n",
              "            b_layer4_1_bn2_num_batches_tracked: BUFFER target='layer4.1.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer4_1_bn3_running_mean: BUFFER target='layer4.1.bn3.running_mean' persistent=True\n",
              "            b_layer4_1_bn3_running_var: BUFFER target='layer4.1.bn3.running_var' persistent=True\n",
              "            b_layer4_1_bn3_num_batches_tracked: BUFFER target='layer4.1.bn3.num_batches_tracked' persistent=True\n",
              "            b_layer4_2_bn1_running_mean: BUFFER target='layer4.2.bn1.running_mean' persistent=True\n",
              "            b_layer4_2_bn1_running_var: BUFFER target='layer4.2.bn1.running_var' persistent=True\n",
              "            b_layer4_2_bn1_num_batches_tracked: BUFFER target='layer4.2.bn1.num_batches_tracked' persistent=True\n",
              "            b_layer4_2_bn2_running_mean: BUFFER target='layer4.2.bn2.running_mean' persistent=True\n",
              "            b_layer4_2_bn2_running_var: BUFFER target='layer4.2.bn2.running_var' persistent=True\n",
              "            b_layer4_2_bn2_num_batches_tracked: BUFFER target='layer4.2.bn2.num_batches_tracked' persistent=True\n",
              "            b_layer4_2_bn3_running_mean: BUFFER target='layer4.2.bn3.running_mean' persistent=True\n",
              "            b_layer4_2_bn3_running_var: BUFFER target='layer4.2.bn3.running_var' persistent=True\n",
              "            b_layer4_2_bn3_num_batches_tracked: BUFFER target='layer4.2.bn3.num_batches_tracked' persistent=True\n",
              "            x: USER_INPUT\n",
              "    \n",
              "            # outputs\n",
              "            linear: USER_OUTPUT\n",
              "    \n",
              "        Range constraints: {}\n",
              "\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.onnx.export(\n",
        "    torch_model,\n",
        "    dummy_input,\n",
        "    ONNX_PATH,\n",
        "    export_params=True,\n",
        "    opset_version=OPSET,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"output\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from onnx import checker\n",
        "\n",
        "onnx_model = onnx.load(ONNX_PATH)\n",
        "checker.check_model(onnx_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Benchmark (Native Pytorch vs ONNX Runtime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "SAMPLES = 1000\n",
        "IMG_SIZE = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pytorch (CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:31<00:00, 32.03it/s]\n"
          ]
        }
      ],
      "source": [
        "pytorch_total_time = 0.0\n",
        "\n",
        "for _ in tqdm(range(SAMPLES)):\n",
        "    x = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        y = torch_model(x)\n",
        "    end_time = time.time()\n",
        "    \n",
        "    pytorch_total_time += (end_time - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pytorch Total Inference Time for 1000 samples: 30.5629 seconds\n"
          ]
        }
      ],
      "source": [
        "print(f\"Pytorch Total Inference Time for {SAMPLES} samples: {pytorch_total_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ONNX Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "session = ort.InferenceSession(\n",
        "    \"resnet50.onnx\",\n",
        "    providers=[\"CPUExecutionProvider\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:13<00:00, 74.52it/s]\n"
          ]
        }
      ],
      "source": [
        "onnx_total_time = 0.0\n",
        "\n",
        "for _ in tqdm(range(SAMPLES)):\n",
        "    x = np.random.randn(1, 3, IMG_SIZE, IMG_SIZE).astype(np.float32)\n",
        "    start_time = time.time()\n",
        "    y = session.run(None, {\"input\": x})\n",
        "    end_time = time.time()\n",
        "    onnx_total_time += (end_time - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX Total Inference Time for 1000 samples: 11.0720 seconds\n"
          ]
        }
      ],
      "source": [
        "print(f\"ONNX Total Inference Time for {SAMPLES} samples: {onnx_total_time:.4f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "onnx-cpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
