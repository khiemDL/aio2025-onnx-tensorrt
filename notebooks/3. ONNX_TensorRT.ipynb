{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyPYTqYUggA1dxJkmBXyo3uJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Introduction**\n","TensorRT là một thư viện được phát triển bởi NVIDIA và là một phần của NVIDIA Deep Learning Accelerator (NVIDIA), dùng để tối ưu hóa mô hình AI, học máy chạy trên GPU. Giúp cải thiện tốc độ và hiệu suất khi triển khai môi hình trên các hệ thống nhúng và máy tính.\n","\n","Bài học này sẽ trình bày cách sủ dụng TensorRT cơ bản cho Post-Training Quantization trên mô hình ResNet18.\n","\n","Quy trình tối ưu hóa với TensorRT:\n","* (1) Chuyển đổi (Conversion) mô hình PyTorch thành dạng trung gian ONNX thông qua hàm torch.onnx.export để tương thích định dạng hỗ trợ của Tensort.\n","\n","* (2) Xây dựng Engine (Building), tại đây TensorRT Builder phân tích đồ thị ONNX và tái cấu trúc mạng lưới, áp dụng các kỹ thuật lượng tử hóa như FP16 hoặc INT8 đi kèm Calibration để tạo ra một file Engine nhị phân (.trt) được tinh chỉnh đặc biệt cho phần cứng GPU đích.\n","\n","* (3) Thực thi (Inference Runtime), file Engine được giải nén vào bộ nhớ, kết hợp với việc quản lý tài nguyên thủ công qua CUDA để vận hành luồng xử lý khép kín: sao chép dữ liệu từ Host xuống Device, thực hiện tính toán song song tốc độ cao, và chuyển kết quả về Host.\n","\n","Lưu ý: Có nhiều cách cài đặt và sử dụng TensorRT (Thông qua API hoặc thư viện `torch-tensorrt` để cài đặt dễ hơn). Trong bài học này chỉ trình bày cách đơn giản nhất để chạy được trên Colab."],"metadata":{"id":"wmgif7m92cWF"}},{"cell_type":"markdown","source":["# **1. Cài đặt thư viện và chuẩn bị dữ liệu**"],"metadata":{"id":"7iEMaHCN29VJ"}},{"cell_type":"markdown","source":["Đầu tiên, chúng ta cần cài đặt TensorRT (phiên bản tương thích với CUDA 12 trên Colab), PyCUDA để giao tiếp với GPU driver, và các thư viện hỗ trợ ONNX. Đồng thời tải file trọng số ResNet18 đã fine-tune trên CIFAR-10."],"metadata":{"id":"F_JHTwAT9g72"}},{"cell_type":"code","source":["!pip install tensorrt==10.0.1 --extra-index-url https://pypi.nvidia.com"],"metadata":{"id":"OdgqUNpy96mL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768130205813,"user_tz":-420,"elapsed":149443,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"5a7ea962-cf93-46f5-9116-e372d0b1fce9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n","Collecting tensorrt==10.0.1\n","  Downloading https://pypi.nvidia.com/tensorrt/tensorrt-10.0.1.tar.gz (16 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorrt-cu12 (from tensorrt==10.0.1)\n","  Downloading https://pypi.nvidia.com/tensorrt-cu12/tensorrt_cu12-10.14.1.48.post1.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorrt_cu12_libs==10.14.1.48.post1 (from tensorrt-cu12->tensorrt==10.0.1)\n","  Downloading https://pypi.nvidia.com/tensorrt-cu12-libs/tensorrt_cu12_libs-10.14.1.48.post1-py2.py3-none-manylinux_2_28_x86_64.whl (3960.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 GB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorrt_cu12_bindings==10.14.1.48.post1 (from tensorrt-cu12->tensorrt==10.0.1)\n","  Downloading https://pypi.nvidia.com/tensorrt-cu12-bindings/tensorrt_cu12_bindings-10.14.1.48.post1-cp312-none-manylinux_2_28_x86_64.whl (879 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.9/879.9 kB\u001b[0m \u001b[31m214.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cuda-toolkit<13,>=12 in /usr/local/lib/python3.12/dist-packages (from cuda-toolkit[cudart]<13,>=12->tensorrt_cu12_libs==10.14.1.48.post1->tensorrt-cu12->tensorrt==10.0.1) (12.9.1)\n","Collecting nvidia-cuda-runtime-cu12==12.9.79.* (from cuda-toolkit[cudart]<13,>=12->tensorrt_cu12_libs==10.14.1.48.post1->tensorrt-cu12->tensorrt==10.0.1)\n","  Downloading https://pypi.nvidia.com/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.9.79-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m249.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt-cu12\n","  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt: filename=tensorrt-10.0.1-py2.py3-none-any.whl size=16331 sha256=c6dfa72394251b5e3eb0522bffa954674c9f76fb77a40ec402758e89e7149862\n","  Stored in directory: /root/.cache/pip/wheels/ed/50/66/94cfda7829c4e8e71565109dc19bab66be78a78c5915ade5e5\n","  Building wheel for tensorrt-cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.14.1.48.post1-py2.py3-none-any.whl size=18166 sha256=f02882a98f619facd7d2f828c0823e0639d5163ebd81b5165c70dbc155880925\n","  Stored in directory: /root/.cache/pip/wheels/62/45/d8/cc48db84eae5237f52611a1a665d77130385ccb4cd1d0d8ae6\n","Successfully built tensorrt tensorrt-cu12\n","Installing collected packages: tensorrt_cu12_bindings, nvidia-cuda-runtime-cu12, tensorrt_cu12_libs, tensorrt-cu12, tensorrt\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.9.0+cu126 requires nvidia-cuda-runtime-cu12==12.6.77; platform_system == \"Linux\", but you have nvidia-cuda-runtime-cu12 12.9.79 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cuda-runtime-cu12-12.9.79 tensorrt-10.0.1 tensorrt-cu12-10.14.1.48.post1 tensorrt_cu12_bindings-10.14.1.48.post1 tensorrt_cu12_libs-10.14.1.48.post1\n"]}]},{"cell_type":"markdown","source":["Cài đặt các thư viện hỗ  trợ"],"metadata":{"id":"MOHA91Q73DfJ"}},{"cell_type":"code","source":["!pip install pycuda onnx onnxruntime onnxscript"],"metadata":{"id":"oCdany7B99qO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768130361923,"user_tz":-420,"elapsed":156103,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"3ca61f79-5eac-4b92-ea0f-05a5f83df67e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pycuda\n","  Downloading pycuda-2025.1.2.tar.gz (1.7 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m1.5/1.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting onnx\n","  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n","Collecting onnxscript\n","  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n","Collecting pytools>=2011.2 (from pycuda)\n","  Downloading pytools-2025.2.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycuda) (4.5.1)\n","Requirement already satisfied: mako in /usr/local/lib/python3.12/dist-packages (from pycuda) (1.3.10)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n","Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n","Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n","  Downloading onnx_ir-0.1.14-py3-none-any.whl.metadata (3.2 kB)\n","Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n","  Downloading siphash24-1.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from mako->pycuda) (3.0.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnx_ir-0.1.14-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytools-2025.2.5-py3-none-any.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading siphash24-1.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pycuda\n","  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycuda: filename=pycuda-2025.1.2-cp312-cp312-linux_x86_64.whl size=659050 sha256=635bfdd1ab8e3bfef47f7b9a115946a3fa4ed0c8f454b27b52eb3dea9e219af9\n","  Stored in directory: /root/.cache/pip/wheels/d5/36/f3/ac5f09d768cad3fa15d5a3449bdfe65c3de58e69d036c73228\n","Successfully built pycuda\n","Installing collected packages: siphash24, humanfriendly, pytools, onnx, coloredlogs, pycuda, onnxruntime, onnx_ir, onnxscript\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.20.1 onnx_ir-0.1.14 onnxruntime-1.23.2 onnxscript-0.5.7 pycuda-2025.1.2 pytools-2025.2.5 siphash24-1.8\n"]}]},{"cell_type":"markdown","source":["Tải file trọng số ResNet18 đã train trên CIFAR 10"],"metadata":{"id":"y6MoOKSM1Qf6"}},{"cell_type":"code","source":["!gdown 1GrQM-axOHvnBcgegvVC2V7z1aaIHb4WS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qCG7ME9jvuGO","executionInfo":{"status":"ok","timestamp":1768130366380,"user_tz":-420,"elapsed":4446,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"ef0cae62-a64a-46d2-e2dd-de49e5d9c5c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1GrQM-axOHvnBcgegvVC2V7z1aaIHb4WS\n","From (redirected): https://drive.google.com/uc?id=1GrQM-axOHvnBcgegvVC2V7z1aaIHb4WS&confirm=t&uuid=cb45c7e6-10dd-4bb0-9b35-c0b4b7d06c7c\n","To: /content/resnet18_cifar10_finetuned.pth\n","100% 44.8M/44.8M [00:01<00:00, 35.4MB/s]\n"]}]},{"cell_type":"markdown","source":["Import các thư viện cần thiết. Lưu ý tensorrt và pycuda là hai thư viện chính để chạy tối ưu hóa."],"metadata":{"id":"NWn6p3oV2uNg"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import time\n","import copy\n","import numpy as np\n","import tensorrt as trt\n","import pycuda.driver as cuda\n","import pycuda.autoinit"],"metadata":{"id":"X_0DQ6VAurEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Chuẩn bị Dataloader (Test & Calibration)"],"metadata":{"id":"6lHmHoD73VO-"}},{"cell_type":"code","source":["test_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# 1. Test Loader\n","test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)\n","\n","# 2. Calibration Loader\n","calib_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=test_transform)\n","calib_subset = torch.utils.data.Subset(calib_set, list(range(500)))\n","calib_loader = torch.utils.data.DataLoader(calib_subset, batch_size=1, shuffle=False)\n"],"metadata":{"id":"xvfRLIufulkY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cài đặt các hàm tiện ích"],"metadata":{"id":"y6u_elV93Xpf"}},{"cell_type":"code","source":["def get_model_size(model, label=\"\"):\n","    \"\"\"\n","    Hàm in kích thước mô hình bằng cách đọc file trọng số.\n","    :param model: Mô hình PyTorch.\n","    :param label: Nhãn tên cho mô hình.\n","    \"\"\"\n","    torch.save(model.state_dict(), \"temp.p\")\n","    size = os.path.getsize(\"temp.p\") / 1e6\n","    print(f\"Model {label} size: {size:.2f} MB\")\n","    os.remove(\"temp.p\")\n","    return size\n","\n","def evaluate_model(model, data_loader, device, max_samples = None, is_tensorrt = False):\n","    \"\"\"Hàm đánh giá hỗ trợ cả PyTorch và TensorRT\"\"\"\n","    correct = 0\n","    total = 0\n","    start_time = time.time()\n","\n","    if not is_tensorrt:\n","        model.eval()\n","        model.to(device)\n","\n","    with torch.no_grad():\n","        for i, (images, labels) in enumerate(data_loader):\n","            if max_samples is not None and i >= max_samples:\n","                break\n","\n","            labels = labels.to(device)\n","\n","            if not is_tensorrt:\n","                images = images.to(device)\n","                outputs = model(images)\n","            else:\n","                outputs = model(images)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    end_time = time.time()\n","    accuracy = 100 * correct / total\n","    inference_time = (end_time - start_time) / total * 1000 # ms/img\n","\n","    print(f\" - Accuracy: {accuracy:.2f}%\")\n","    print(f\" - Running time ({min(total, max_samples)} samples): {inference_time:.4f} second\")\n","\n","    return accuracy, inference_time\n","\n","def print_comparison(title, size_fp32, size_dyn, size_stat, time_fp32, time_dyn, time_stat, acc_fp32, acc_dyn, acc_stat):\n","    size_rate_dyn = size_fp32 / size_dyn\n","    size_rate_stat = size_fp32 / size_stat\n","    time_rate_dyn = time_fp32 / time_dyn\n","    time_rate_stat = time_fp32 / time_stat\n","    acc_delta_dyn = acc_fp32 - acc_dyn\n","    acc_delta_stat = acc_fp32 - acc_stat\n","\n","    print(\"=\" * 10 + f\" {title} \" + \"=\" * 10)\n","    print(f\"{'Metric':<20} | {'FP32':<12} | {'INT8 Dyn':<12} | {'INT8 Stat':<12} | {'Cải thiện (Dyn/Stat)':<20}\")\n","    print(\"-\" * 95)\n","    print(f\"{'Size (MB)':<20} | {size_fp32:>8.2f} MB | {size_dyn:>8.2f} MB  | {size_stat:>8.2f} MB  | Giảm {size_rate_dyn:.2f}x / {size_rate_stat:.2f}x\")\n","    print(f\"{'Accuracy (%)':<20} | {acc_fp32:>8.2f}%  | {acc_dyn:>8.2f}%   | {acc_stat:>8.2f}%   | Delta {acc_delta_dyn:+.2f}% / {acc_delta_stat:+.2f}%\")\n","    print(f\"{'Latency (s)':<20} | {time_fp32:>8.4f}s | {time_dyn:>8.4f}s | {time_stat:>8.4f}s | x{time_rate_dyn:.2f} / x{time_rate_stat:.2f} speedup\")\n","    print(\"=\" * 50)"],"metadata":{"id":"hjXxHMImw4Rk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Kiểm tra TensorRT"],"metadata":{"id":"y_tDrq6z3bJo"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3NifbUJVEwtN","executionInfo":{"status":"ok","timestamp":1768130389490,"user_tz":-420,"elapsed":24,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"68c8c176-384d-4d06-eb50-3fac113abe79"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorRT version: 10.14.1.48.post1\n","TensorRT Builder created successfully! (CUDA driver matches)\n"]}],"source":["import os\n","import sys\n","\n","try:\n","    import tensorrt as trt\n","    print(f\"TensorRT version: {trt.__version__}\")\n","    logger = trt.Logger(trt.Logger.WARNING)\n","    builder = trt.Builder(logger)\n","    print(\"TensorRT Builder created successfully!\")\n","except ImportError:\n","    print(\"TensorRT not found!\")\n","except Exception as e:\n","    print(f\"Error initializing TensorRT: {e}\")"]},{"cell_type":"markdown","source":[" # **2. Quantize mô hình ResNet18 xuống FP16 và INT8 bằng TensorRT**"],"metadata":{"id":"ZWkZ5gld3etf"}},{"cell_type":"markdown","source":["## 2.1. Khai báo mô hình, load trọng số và tính toán trên mô hình FP32"],"metadata":{"id":"cexr9gaF4Bdm"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_resnet18 = torchvision.models.resnet18(pretrained=False)\n","model_resnet18.fc = nn.Linear(512, 10)\n","\n","weights_path = 'resnet18_cifar10_finetuned.pth'\n","if os.path.exists(weights_path):\n","    model_resnet18.load_state_dict(torch.load(weights_path, map_location=device))\n","else:\n","    print(\"Không tìm thấy file weights\")\n","\n","model_resnet18.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eYo2xcVAFCfT","executionInfo":{"status":"ok","timestamp":1768130714908,"user_tz":-420,"elapsed":295,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"18f3c677-ea68-443f-8672-44ec423f97ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Lấy các thông số đánh giá của mô hình FP32."],"metadata":{"id":"Re-qxTgkdMcR"}},{"cell_type":"code","source":["acc_fp32, time_fp32 = evaluate_model(model_resnet18, test_loader, device, max_samples = 500)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rYeV7_pza_G","executionInfo":{"status":"ok","timestamp":1768130724092,"user_tz":-420,"elapsed":3505,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"ce6749ad-9116-47ba-b0d2-329d096d47c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" - Accuracy: 93.00%\n"," - Running time (500 samples): 6.9641 second\n"]}]},{"cell_type":"markdown","source":["\n","## 2.2. TensorRT <br> **Step 1**: Chuyển đổi file trọng số của mô hình sang định dạng `ONNX`.\n","TensorRT không đọc trực tiếp file `.pth` của PyTorch. Chúng ta cần convert mô hình sang một định dạng khác là `ONNX`."],"metadata":{"id":"3TzBtTcG4mDq"}},{"cell_type":"markdown","source":["1. Đầu tiên tạo một dummpy_input, input này được truyền qua mô hình một lần, giúp `torch.onnx.export` truy vết được cấu trúc của mô hình."],"metadata":{"id":"_21x_nCU6sdt"}},{"cell_type":"code","source":["dummy_input = torch.randn(1, 3, 224, 224, device='cuda')"],"metadata":{"id":"x6VRfgwc5Z-9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Dùng phương thức ` torch.onnx.export()` để chuyển đổi sang ONNX.\n","\n","\n","`export_params` =:\n","\n","*  True: Lưu cả kiến trúc lẫn trọng số vào file ONNX.\n","\n","*  False: Chỉ lưu khung mô hình\n","\n","`opset_version `: ONNX có nhiều phiên bản tập lệnh (opset). Số 18 là một phiên bản khá mới. Chọn version cao giúp hỗ trợ nhiều toán tử phức tạp hơn, nhưng cần đảm bảo bản TensorRT bạn cài đặt hỗ trợ version này.\n","\n","`do_constant_folding` = True: Tối ưu tính toán: Ví dụ: Nếu trong mạng có phép tính 2 * 3, thay vì lưu phép nhân, nó sẽ tính luôn ra 6 và lưu số 6 vào. Việc này giúp mô hình gọn nhẹ hơn.\n","\n","`input_names = ['input']` & `output_names=['output']`: Gán nhãn cho cổng vào và cổng ra của file ONNX. Sau này khi viết code TensorRT chỉ cần gọi đúng tên `input` và `output` này để đẩy dữ liệu vào và lấy kết quả ra."],"metadata":{"id":"MB_uFWXX7F_C"}},{"cell_type":"code","source":["onnx_file_path = \"resnet18.onnx\"\n","\n","print(f\"Exporting to ONNX: {onnx_file_path}...\")\n","\n","torch.onnx.export(\n","    model_resnet18,\n","    dummy_input,\n","    onnx_file_path,\n","    export_params=True,\n","    opset_version=18,\n","    do_constant_folding=True,\n","    input_names=['input'],\n","    output_names=['output'],\n",")\n","print(\" Export ONNX !\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AF7tDdASwEnY","executionInfo":{"status":"ok","timestamp":1768130746121,"user_tz":-420,"elapsed":4456,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"f146f577-1b7a-4a3a-975b-f415ffcc1fce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Exporting to ONNX: resnet18.onnx...\n","[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`...\n","[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n","[torch.onnx] Run decomposition...\n","[torch.onnx] Run decomposition... ✅\n","[torch.onnx] Translate the graph into ONNX...\n","[torch.onnx] Translate the graph into ONNX... ✅\n","Applied 40 of general pattern rewrite rules.\n"," Export ONNX !\n"]}]},{"cell_type":"markdown","source":["## 2.2. TensorRT <br> **Step 2**: Cài đặt quantization"],"metadata":{"id":"28V-TbE6eSOw"}},{"cell_type":"markdown","source":["Viết class hỗ trợ Calibration khi quantize về INT8 bằng TensorRT. Class này thừa kế `trt.IInt8EntropyCalibrator2`, là một thuật toán hỗ trợ sẵn để giảm thiếu mất mát khi nén dữ liệu."],"metadata":{"id":"iYSLgW4afSJw"}},{"cell_type":"code","source":["class ResNetEntropyCalibrator(trt.IInt8EntropyCalibrator2):\n","    def __init__(self, dataloader, cache_file=\"resnet18_calibration.cache\"):\n","        super().__init__()\n","        self.dataloader = dataloader\n","        self.data_iter = iter(dataloader)\n","        self.cache_file = cache_file #Cache dữ liệu để tăng tốc độ\n","        self.batch_size = dataloader.batch_size\n","        self.current_batch = 0\n","        self.max_batches = 100 # Calibrate 100 batches\n","        self.device_input = cuda.mem_alloc(self.batch_size * 3 * 224 * 224 * 4) #Sử dụng pycuda để xin cấp phát một vùng nhớ trên GPU đủ chứa một batch ảnh đầu vào\n","\n","    def get_batch_size(self): #\n","        \"\"\"\n","        TensorRT gọi hàm này để biết kích thước batch size nạp vào\n","        \"\"\"\n","        return self.batch_size\n","\n","    def get_batch(self, names):\n","        \"\"\"\n","        Quan trọng nhất.\n","        TensorRT sẽ gọi hàm này lặp đi lặp lại trong quá trình build engine để lấy dữ liệu cho đến khi hàm trả về None\n","        \"\"\"\n","        if self.current_batch >= self.max_batches: return None\n","        try:\n","            data, _ = next(self.data_iter)\n","            batch_data = np.ascontiguousarray(data.numpy().astype(np.float32)) #Chuyển dữ liệu sang dạng mảng numpy liên tục trong bộ nhớ để copy cho an toàn\n","            cuda.memcpy_htod(self.device_input, batch_data) #Host to Device. Copy dữ liệu từ CPU sang vùng nhớ GPU (Device) mà ta đã cấp phát ở __init__.\n","            self.current_batch += 1\n","            return [int(self.device_input)] #Trả về địa chỉ bộ nhớ của dữ liệu trên GPU cho TensorRT xử lý.\n","        except StopIteration: return None\n","\n","    def read_calibration_cache(self):\n","        \"\"\"\n","        Đọc kết quả hiệu chuẩn.\n","        \"\"\"\n","        return open(self.cache_file, \"rb\").read() if os.path.exists(self.cache_file) else None\n","\n","    def write_calibration_cache(self, cache):\n","        \"\"\"\n","        Lưu kết quả hiệu chuẩn vào file cache.\n","        \"\"\"\n","        open(self.cache_file, \"wb\").write(cache)"],"metadata":{"id":"pT8YvGCXFGPh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_engine(onnx_path, engine_path, mode='fp16', dataloader=None):\n","    logger = trt.Logger(trt.Logger.WARNING) #Ghi log\n","    builder = trt.Builder(logger) #builder có nhiệm vụ xây engine\n","    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) #Tạo nơi chứa định nghĩa mô hình, cờ EXPLICIT_BATCH là bắt buộc với ONNX.\n","    parser = trt.OnnxParser(network, logger) #Đọc file onnx\n","    config = builder.create_builder_config()\n","\n","    with open(onnx_path, 'rb') as model: #Đọc file onnx\n","        parser.parse(model.read())\n","\n","    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30) # Vùng nhớ tạm thời TensorRT dùng để thử nghiệm các thuật toán tối ưu, 2^30 = 1GB\n","\n","    if mode == 'fp16' and builder.platform_has_fast_fp16: #Lựa chọn tối ưu về fp16\n","        config.set_flag(trt.BuilderFlag.FP16) #Gắn cờ vào config()\n","    elif mode == 'int8' and builder.platform_has_fast_int8: #Lựa chọn tối ưu về int8\n","        config.set_flag(trt.BuilderFlag.INT8)\n","        config.int8_calibrator = ResNetEntropyCalibrator(dataloader, f\"calib_{mode}.cache\")\n","\n","    print(f\"Building {mode} engine...\")\n","    serialized_engine = builder.build_serialized_network(network, config) # Bắt đầu nén\n","    with open(engine_path, \"wb\") as f:\n","        f.write(serialized_engine)\n","    print(f\"✅ Saved: {engine_path}\")"],"metadata":{"id":"IatToahOwXPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["build_engine(onnx_file_path, \"resnet18_fp16.trt\", mode='fp16')\n","build_engine(onnx_file_path, \"resnet18_int8.trt\", mode='int8', dataloader=calib_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NuI1BPrfwYbt","executionInfo":{"status":"ok","timestamp":1768130825670,"user_tz":-420,"elapsed":49222,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"e3c98fbd-f7c7-4795-cb46-7496f6fe9906"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Building fp16 engine...\n","✅ Saved: resnet18_fp16.trt\n","Building int8 engine...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3659170000.py:17: DeprecationWarning: Use Deprecated in TensorRT 10.1. Superseded by explicit quantization. instead.\n","  config.int8_calibrator = ResNetEntropyCalibrator(dataloader, f\"calib_{mode}.cache\")\n"]},{"output_type":"stream","name":"stdout","text":["✅ Saved: resnet18_int8.trt\n"]}]},{"cell_type":"markdown","source":["Class `TRTModuleWrapper` thừa kế từ `nn.Module` của PyTorch. Mục đích là để đóng giả một layer PyTorch, nhưng bên trong lại chạy bằng động cơ TensorRT. Nhờ vậy, bạn có thể tái sử dụng toàn bộ code đánh giá (evaluate_model) cũ mà không cần sửa đổi gì."],"metadata":{"id":"wJF7YcmFanns"}},{"cell_type":"code","source":["class TRTModuleWrapper(nn.Module):\n","    def __init__(self, engine_path):\n","        super().__init__()\n","        self.logger = trt.Logger(trt.Logger.WARNING)\n","        self.runtime = trt.Runtime(self.logger) #trt.Runtime để đọc file engine.\n","\n","        with open(engine_path, \"rb\") as f:\n","            self.engine = self.runtime.deserialize_cuda_engine(f.read()) #Đọc file nhị phân .trt từ ổ cứng và giải nén nó thành đối tượng self.engine để sẵn sàng sử dụng.\n","\n","        self.context = self.engine.create_execution_context() #môi trường thực thi\n","\n","        # TensorRT yêu cầu bạn phải tự quản lý bộ nhớ thủ công.\n","        # Vòng lặp for sau sẽ thực hiện:\n","            # Duyệt qua từng đầu vào/đầu ra của mô hình để xem nó cần bao nhiêu bytes.\n","            # Sử dụng cuda.pagelocked_empty để copy dữ liệu sang GPU nhanh gấp đôi so với bộ nhớ RAM thường.\n","            # Sử dụng cuda.mem_alloc để xin VRAM trên GPU.\n","            # Lưu lại địa chỉ của các vùng nhớ này để chỉ cho TensorRT biết chỗ nào chứa ảnh, chỗ nào chứa kết quả\n","        self.inputs = []\n","        self.outputs = []\n","        self.allocations = []\n","        self.stream = cuda.Stream()\n","\n","        for i in range(self.engine.num_io_tensors):\n","            name = self.engine.get_tensor_name(i)\n","            # Lấy shape và dtype\n","            shape = self.engine.get_tensor_shape(name)\n","            dtype = self.engine.get_tensor_dtype(name)\n","\n","            # Tính toán kích thước bộ nhớ cần thiết\n","            size = trt.volume(shape)\n","            numpy_dtype = trt.nptype(dtype)\n","\n","            # Cấp phát Host (CPU) và Device (GPU) memory\n","            host_mem = cuda.pagelocked_empty(size, numpy_dtype)\n","            device_mem = cuda.mem_alloc(host_mem.nbytes)\n","\n","            self.allocations.append(int(device_mem))\n","            self.context.set_tensor_address(name, int(device_mem))\n","\n","            # Lưu binding info\n","            # Lưu shape dưới dạng tuple ngay từ đây để dùng về sau\n","            binding = {\n","                'name': name,\n","                'host': host_mem,\n","                'device': device_mem,\n","                'shape': tuple(shape)\n","            }\n","\n","            if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n","                self.inputs.append(binding)\n","            else:\n","                self.outputs.append(binding)\n","\n","    def forward(self, x):\n","        # x là PyTorch Tensor (Batch, 3, 224, 224)\n","        # 1. Copy Tensor -> Numpy -> Host Buffer\n","        input_np = x.cpu().numpy().ravel()\n","        np.copyto(self.inputs[0]['host'], input_np)\n","\n","        # 2. Host -> Device\n","        cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)\n","\n","        # 3. Infer\n","        self.context.execute_async_v3(stream_handle=self.stream.handle)\n","\n","        # 4. Device -> Host\n","        cuda.memcpy_dtoh_async(self.outputs[0]['host'], self.outputs[0]['device'], self.stream)\n","        self.stream.synchronize()\n","\n","        # 5. Return Tensor (Batch, Classes)\n","        output_data = self.outputs[0]['host']\n","\n","        # Lấy shape đã được convert sang tuple ở hàm __init__\n","        output_shape = self.outputs[0]['shape']\n","\n","        return torch.from_numpy(output_data).reshape(output_shape).to(x.device)\n"],"metadata":{"id":"qjxo60njwezP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Bảng so sánh**"],"metadata":{"id":"4rl6lG08btcd"}},{"cell_type":"code","source":["import os\n","def get_file_size_mb(file_path):\n","    if os.path.exists(file_path):\n","        return os.path.getsize(file_path) / 1e6\n","    return 0\n","\n","# Kiểm tra file tồn tại trước khi chạy\n","if os.path.exists(\"resnet18_fp16.trt\") and os.path.exists(\"resnet18_int8.trt\"):\n","    # Load Engines\n","    trt_fp16 = TRTModuleWrapper(\"resnet18_fp16.trt\")\n","    trt_int8 = TRTModuleWrapper(\"resnet18_int8.trt\")\n","\n","    print(\"Evaluating TRT FP16...\")\n","    acc_fp16, lat_fp16 = evaluate_model(trt_fp16, test_loader, device, max_samples=500, is_tensorrt=True)\n","    size_fp16 = get_file_size_mb(\"resnet18_fp16.trt\")\n","\n","    print(\"Evaluating TRT INT8...\")\n","    acc_int8, lat_int8 = evaluate_model(trt_int8, test_loader, device, max_samples=500, is_tensorrt=True)\n","    size_int8 = get_file_size_mb(\"resnet18_int8.trt\")\n","\n","    # 3. Tổng hợp kết quả\n","    size_pt = get_file_size_mb(weights_path) if os.path.exists(weights_path) else 0\n","\n","    print(f\"\\n{'Method':<15} | {'Size (MB)':<10} | {'Acc (%)':<10} | {'Time (ms)':<15} | {'Speedup':<10}\")\n","    print(\"-\" * 75)\n","    print(f\"{'PyTorch FP32':<15} | {size_pt:<10.2f} | {acc_pt:<10.2f} | {lat_pt:<15.2f} | {'1.0x':<10}\")\n","    print(f\"{'TRT FP16':<15} | {size_fp16:<10.2f} | {acc_fp16:<10.2f} | {lat_fp16:<15.2f} | {lat_pt/lat_fp16:<10.2f}\")\n","    print(f\"{'TRT INT8':<15} | {size_int8:<10.2f} | {acc_int8:<10.2f} | {lat_int8:<15.2f} | {lat_pt/lat_int8:<10.2f}\")\n","\n","else:\n","    print(\"Error: Không tìm thấy file .trt!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6hweWPi40WCS","executionInfo":{"status":"ok","timestamp":1768131154577,"user_tz":-420,"elapsed":4468,"user":{"displayName":"Phat Dat To","userId":"12579648227497838035"}},"outputId":"158ff627-a607-4953-fdba-d06cdc34a406"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating TRT FP16...\n"," - Accuracy: 93.00%\n"," - Running time (500 samples): 4.6443 second\n","Evaluating TRT INT8...\n"," - Accuracy: 92.80%\n"," - Running time (500 samples): 3.9797 second\n","\n","Method          | Size (MB)  | Acc (%)    | Time (ms)       | Speedup   \n","---------------------------------------------------------------------------\n","PyTorch FP32    | 44.81      | 93.00      | 6.96            | 1.0x      \n","TRT FP16        | 22.61      | 93.00      | 4.64            | 1.50      \n","TRT INT8        | 11.79      | 92.80      | 3.98            | 1.75      \n"]}]}]}