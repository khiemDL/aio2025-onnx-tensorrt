{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16fcbd89",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09240cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d93e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 16 16:27:58 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| 54%   51C    P3             36W /  170W |     639MiB /  12288MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            4290      G   /usr/lib/xorg/Xorg                      127MiB |\n",
      "|    0   N/A  N/A            4592      G   /usr/bin/gnome-shell                      8MiB |\n",
      "|    0   N/A  N/A            5114      G   ...exec/xdg-desktop-portal-gnome          2MiB |\n",
      "|    0   N/A  N/A           39940      G   /usr/share/code/code                     34MiB |\n",
      "|    0   N/A  N/A         1740744      G   .../7559/usr/lib/firefox/firefox         18MiB |\n",
      "|    0   N/A  N/A         1746638      G   /usr/share/code/code                     43MiB |\n",
      "|    0   N/A  N/A         3901779      G   /usr/bin/nautilus                        19MiB |\n",
      "|    0   N/A  N/A         3903983      G   .../7559/usr/lib/firefox/firefox          5MiB |\n",
      "|    0   N/A  N/A         3915174      G   /usr/lib/xorg/Xorg                      198MiB |\n",
      "|    0   N/A  N/A         3915499      G   /usr/bin/gnome-shell                      6MiB |\n",
      "|    0   N/A  N/A         3916015      G   /usr/libexec/gnome-initial-setup          9MiB |\n",
      "|    0   N/A  N/A         3916640      G   /usr/bin/nautilus                        14MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042de26e",
   "metadata": {},
   "source": [
    "## 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57fe8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PATH = \"/home/mlops/Repository/aio2025-onnx-tensorrt/models/yolo26l.onnx\"\n",
    "IMAGE_GLOB = \"/home/mlops/Repository/aio2025-onnx-tensorrt/images/val2014/*.jpg\"\n",
    "IMG_SIZE = 640\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "WARMUP = 20\n",
    "SAMPLE_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a58e1",
   "metadata": {},
   "source": [
    "## 3. Preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b85386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, size=640):\n",
    "    img = cv2.resize(img, (size, size))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = np.expand_dims(img, 0)\n",
    "    return torch.from_numpy(img)\n",
    "\n",
    "# Load images\n",
    "image_paths = sorted(glob.glob(IMAGE_GLOB))\n",
    "assert len(image_paths) > 0, \"No images found\"\n",
    "if SAMPLE_SIZE != -1:\n",
    "    image_paths = image_paths[:SAMPLE_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43e82b",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9182e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/mlops/Repository/aio2025-onnx-tensorrt/models/yolo26l.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime 1.21.0 with CUDAExecutionProvider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2026-01-16 16:27:59.117041866 [W:onnxruntime:, transformer_memcpy.cc:83 ApplyImpl] 6 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = YOLO(ONNX_PATH, task='detect')\n",
    "\n",
    "# Warmup\n",
    "dummy = torch.zeros((1, 3, IMG_SIZE, IMG_SIZE), device=DEVICE)\n",
    "for _ in range(WARMUP):\n",
    "    _ = model(dummy, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30336bf6",
   "metadata": {},
   "source": [
    "## 5. Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb5653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 38.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# FPS test\n",
    "start = time.perf_counter()\n",
    "\n",
    "for p in tqdm(image_paths):\n",
    "    img = cv2.imread(p)\n",
    "    inp = preprocess(img, IMG_SIZE).to(DEVICE)\n",
    "    _ = model(inp, verbose=False)\n",
    "end = time.perf_counter()\n",
    "\n",
    "total_time = end - start\n",
    "fps = len(image_paths) / total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f9365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Device           : cuda\n",
      "Images processed : 1000\n",
      "Total time       : 25.69 s\n",
      "FPS              : 38.93\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 40)\n",
    "print(f\"Device           : {DEVICE}\")\n",
    "print(f\"Images processed : {len(image_paths)}\")\n",
    "print(f\"Total time       : {total_time:.2f} s\")\n",
    "print(f\"FPS              : {fps:.2f}\")\n",
    "print(\"=\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx_tensorrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
